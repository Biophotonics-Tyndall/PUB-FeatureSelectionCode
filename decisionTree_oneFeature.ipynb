{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Classifier using One Feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import matplotlib.transforms\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from itertools import combinations\n",
    "import time\n",
    "from joblib import dump"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to data directory\n",
    "\n",
    "work_path = os.getcwd()\n",
    "print(work_path)\n",
    "\n",
    "os.chdir('YOUR DATA DIRECTORY')\n",
    "data_path = os.getcwd()\n",
    "print(data_path)\n",
    "os.chdir(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "os.chdir(data_path)\n",
    "\n",
    "# Load dataset - df\n",
    "df = pd.read_csv('YOUR DATA FILE.csv')\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_by_y = df.groupby(['target_y']).mean()\n",
    "stdev_df_by_y = df.groupby(['target_y']).std()\n",
    "\n",
    "# Column names to numerical\n",
    "col_wavelengths = df.columns.drop('target_y')\n",
    "col_wavelengths = col_wavelengths.astype(np.float64)\n",
    "print('Number of wavelengths: ', len(col_wavelengths))\n",
    "\n",
    "# Legend labels\n",
    "tissue_types = df['target_y'].unique()\n",
    "tissue_types.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SG Smoothing of the raw data - Gentle smoothing with w/p = 2.5 to get rid of some baseline noise\n",
    "\n",
    "# Features\n",
    "X_raw = df.drop(['target_y'], axis=1)\n",
    "\n",
    "# Target\n",
    "y = df['target_y']\n",
    "\n",
    "# Spectral Smoothing - Savitzkyâ€“Golay (SG) method\n",
    "w = 5\n",
    "p = 2\n",
    "X_smooth = savgol_filter(X_raw, w, polyorder=p, axis=1, deriv=0)\n",
    "\n",
    "# Smoothed dataframe\n",
    "df_smooth = pd.DataFrame(X_smooth, columns = col_wavelengths.astype(\"string\"))\n",
    "df_smooth = pd.concat([df_smooth, y.rename('target_y')], axis=1)\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_by_y_smooth = df_smooth.groupby(['target_y']).mean()\n",
    "stdev_df_by_y_smooth = df_smooth.groupby(['target_y']).std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save path\n",
    "os.chdir(work_path)\n",
    "os.chdir('YOUR SAVE PATH')\n",
    "save_path = os.getcwd()\n",
    "print(save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to evaluate the model using classification metrics\n",
    "def model_eval(X, y, model, cross_val):\n",
    "\n",
    "    # define model\n",
    "    clf_model = model\n",
    "\n",
    "    # define cross validation\n",
    "    cross_validation = cross_val\n",
    "\n",
    "    # Initiate empty lists\n",
    "    clf_accuracy_scores = [] # Calculate classification scores\n",
    "    clf_balanced_scores = [] # Calculate balanced classification scores\n",
    "    clf_importance_scores = [] # Calculate model coefficients\n",
    "    clf_reports = [] # Calculate Classification reports\n",
    "    conf_matrix_lists = [] # Calculate Confusion Matrices\n",
    "    clf_kappa_scores = [] # Calculate Cohan Kappa Coefficients\n",
    "\n",
    "    # Evaluate model and calculate metrics\n",
    "    count = 0\n",
    "    for train_index, test_index in cross_validation.split(X, y):\n",
    "\n",
    "        count+=1\n",
    "        #print(count, \" of \",  cross_validation.get_n_splits(), \" CV folds \", end=\"\\r\")\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Fit model\n",
    "        clf_model.fit(X_train, y_train)\n",
    "\n",
    "        # Find coefficients - importance\n",
    "        clf_importance = np.abs(clf_model.feature_importances_)\n",
    "\n",
    "        # Predict using the fitted model\n",
    "        y_predict = clf_model.predict(X_test)\n",
    "\n",
    "        # Calculate classification accuracy score\n",
    "        clf_score = accuracy_score(y_test, y_predict)\n",
    "\n",
    "        # Calculate balanced classification accuracy score\n",
    "        clf_balanced_score = balanced_accuracy_score(y_test, y_predict)\n",
    "\n",
    "        # Calculate classification report\n",
    "        clf_metric = classification_report(y_test, y_predict, digits=4, output_dict=True, zero_division=0)\n",
    "\n",
    "        # Calculate confusion matrix\n",
    "        con_map = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "        # Store each iteration\n",
    "        clf_accuracy_scores.append(clf_score)\n",
    "        clf_balanced_scores.append(clf_balanced_score)\n",
    "        clf_importance_scores.append(clf_importance)\n",
    "        clf_reports.append(clf_metric)\n",
    "        conf_matrix_lists.append(con_map)\n",
    "\n",
    "    return clf_balanced_scores, clf_accuracy_scores, clf_importance_scores, clf_reports, conf_matrix_lists, clf_kappa_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The OVO Approach\n",
    "No Validation Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define random state\n",
    "random_state = 42\n",
    "\n",
    "# Define classification model - Decision Tree\n",
    "dt_model_binary = DecisionTreeClassifier(max_depth = 2,random_state=42)\n",
    "\n",
    "# Define model evaluation method\n",
    "cv_binary = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)\n",
    "\n",
    "# Define binary combinations\n",
    "list_tissue_comb = list(combinations(tissue_types,2))\n",
    "if not os.path.exists('order_of_tissue_comb.joblib'):\n",
    "    dump(list_tissue_comb, 'order_of_tissue_comb.joblib')\n",
    "\n",
    "# Initiate lists for storing\n",
    "# All averaged accuracy scores and standard deviations for all combinations\n",
    "all_avg_accuracy_binary = []\n",
    "all_avg_std_binary = []\n",
    "# All classification metrics for all combinations\n",
    "all_accuracy_binary = []\n",
    "all_clf_reports_binary = []\n",
    "all_conf_matrix_lists_binary = []\n",
    "all_importance_binary = []\n",
    "all_kappa_scores_binary = []\n",
    "# Total time of execution\n",
    "total_time = []\n",
    "\n",
    "print('The total number of combinations: ', len(list_tissue_comb))\n",
    "print('\\n')\n",
    "print('Feature Selection: Only ONE feature\\n')\n",
    "print('Classification Model: Decision tree with max_depth = 2')\n",
    "print('Cross Validation: Repeated stratified K fold with n_splits = 10 and n_repeats = 10')\n",
    "print('\\n')\n",
    "\n",
    "count = 0\n",
    "for i,k in combinations(tissue_types,2):\n",
    "\n",
    "    # Track timestamp - elapsed time\n",
    "    start_time = time.time()\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # if count == 2:\n",
    "    #     print('count = 2; break')\n",
    "    #     break\n",
    "\n",
    "    print('Iteration: ', count)\n",
    "    print('First label: ', i)\n",
    "    print('Second label: ',k)\n",
    "\n",
    "    # Data selection\n",
    "    binary_subset = df.loc[(df['target_y'] == i) + (df['target_y'] == k)]\n",
    "\n",
    "    # Features\n",
    "    X_binary = binary_subset.drop(['target_y'], axis=1)\n",
    "    # Target\n",
    "    y_binary = binary_subset['target_y']\n",
    "\n",
    "    # Evaluate model accuracy - binary clf\n",
    "    # Averaged accuracy scores and standard deviations for each combination\n",
    "    avg_accuracy_binary = []\n",
    "    avg_std_binary = []\n",
    "    # Classification metrics for each combination\n",
    "    accuracy_binary = []\n",
    "    clf_reports_binary = []\n",
    "    conf_matrix_lists_binary = []\n",
    "    importance_binary = []\n",
    "    kappa_scores_binary = []\n",
    "    print('Model Evaluation Starts:')\n",
    "    for n in range(X_binary.shape[1]):\n",
    "        print('Wavelength: ', col_wavelengths[n])\n",
    "        binary_1Feature = pd.DataFrame(X_binary.iloc[:,n].values.reshape(-1,1))\n",
    "        accuracy_scores, importance_scores, clf_reports, conf_matrix_lists, kappa_scores = model_eval(binary_1Feature,y_binary,\n",
    "                                                                                                      dt_model_binary, cv_binary)\n",
    "        print('Clf Accuracy: %.3f +- %.3f %%' % (np.mean(accuracy_scores)*100, np.std(accuracy_scores)*100))\n",
    "        avg_accuracy_binary.append(np.mean(accuracy_scores)*100)\n",
    "        avg_std_binary.append(np.std(accuracy_scores)*100)\n",
    "        accuracy_binary.append(accuracy_scores)\n",
    "        importance_binary.append(importance_scores)\n",
    "        clf_reports_binary.append(clf_reports)\n",
    "        conf_matrix_lists_binary.append(conf_matrix_lists)\n",
    "        kappa_scores_binary.append(kappa_scores)\n",
    "\n",
    "    # Store calculations from each combination in lists\n",
    "    all_avg_accuracy_binary.append(avg_accuracy_binary)\n",
    "    all_avg_std_binary.append(avg_std_binary)\n",
    "    all_accuracy_binary.append(accuracy_binary)\n",
    "    all_importance_binary.append(importance_binary)\n",
    "    all_clf_reports_binary.append(clf_reports_binary)\n",
    "    all_conf_matrix_lists_binary.append(conf_matrix_lists_binary)\n",
    "    all_kappa_scores_binary.append(kappa_scores_binary)\n",
    "\n",
    "    # Plot and Save Accuracy vs. Wavelengths\n",
    "    # Set the figure size\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Tight layout\n",
    "    f.tight_layout()\n",
    "    # Set colors\n",
    "    ax.set_prop_cycle('color',cm.Spectral(np.linspace(0,1,11)))\n",
    "    # Plot\n",
    "    plt.plot(col_wavelengths, avg_accuracy_binary)\n",
    "    pos_std = np.array(avg_accuracy_binary) + np.array(avg_std_binary)\n",
    "    neg_std = np.array(avg_accuracy_binary) - np.array(avg_std_binary)\n",
    "    ax.fill_between(col_wavelengths, neg_std, pos_std, alpha = 0.2)\n",
    "    # Set figure object\n",
    "    ax.set_title('Accuracy of ' + str(i) + ' vs. ' + str(k))\n",
    "    ax.set_xlabel('Wavelength (nm)')\n",
    "    ax.set_ylabel('Classification Accuracy (%)')\n",
    "    ax.xaxis.set_ticks(np.arange(400, 1850, 100))\n",
    "    ax.set_xlim([350,1850])\n",
    "    bbox = matplotlib.transforms.Bbox([[-0.2, -0.36], [10.3, 8.56]])\n",
    "    # Save figure\n",
    "    if not os.path.exists(str(i) + '_' + str(k) + '_clf_accuracy.png'):\n",
    "        f.savefig(save_path + '/' +  str(i) + '_' + str(k) + '_clf_accuracy.png', dpi = 1080, bbox_inches =bbox)\n",
    "\n",
    "    # End timestamp\n",
    "    end_time = time.time()\n",
    "    print('Time to run: ', end_time - start_time, ' seconds')\n",
    "    total_time.append(end_time - start_time)\n",
    "    print('\\n')\n",
    "\n",
    "print('Total time to run: ', sum(total_time)/3600, ' hours')\n",
    "print('END')\n",
    "\n",
    "# Save result variables\n",
    "dump(all_avg_accuracy_binary, 'all_avg_accuracy_binary.joblib')\n",
    "dump(all_avg_std_binary, 'all_avg_std_binary.joblib')\n",
    "dump(all_accuracy_binary, 'all_accuracy_binary.joblib')\n",
    "dump(all_importance_binary, 'all_importance_binary.joblib')\n",
    "dump(all_clf_reports_binary, 'all_clf_reports_binary.joblib')\n",
    "dump(all_conf_matrix_lists_binary, 'all_conf_matrix_lists_binary.joblib')\n",
    "dump(all_kappa_scores_binary, 'all_kappa_scores_binary.joblib')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The OVR Approach\n",
    "No Validation Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save_path\n",
    "os.chdir(save_path)\n",
    "os.chdir('YOUR SAVE PATH - SUBFOLDER')\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "df_dataset = df_smooth\n",
    "tissue_types = tissue_types\n",
    "\n",
    "# Set global random state\n",
    "random_state = 42\n",
    "\n",
    "# Define cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)\n",
    "\n",
    "# Bone Cement = 1 vs. [Cortical Bone, Trabecular Bone, Cartilage, Bone Marrow] = 0\n",
    "# i = 'boneCement'\n",
    "# k_1 = 'cortBone'\n",
    "# k_2 = 'traBone'\n",
    "# k_3 = 'cartilage'\n",
    "# k_4 = 'boneMarrow'\n",
    "\n",
    "# Cortical Bone = 1 vs. [Trabecular Bone, Cartilage, Bone Marrow, Muscle] = 0\n",
    "i = 'cortBone'\n",
    "k_1 = 'traBone'\n",
    "k_2 = 'muscle'\n",
    "k_3 = 'cartilage'\n",
    "k_4 = 'boneMarrow'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# boneCement vs. Rest\n",
    "# cortBone vs. Rest\n",
    "\n",
    "# Data selection for multiple tissue types\n",
    "df_subset_ovr = df_dataset[df_dataset['target_y'].isin([i, k_1, k_2, k_3, k_4])]\n",
    "binary_subset = df_dataset[df_dataset['target_y'].isin([i, k_1, k_2, k_3, k_4])]\n",
    "binary_subset.loc[df['target_y'].isin([k_1, k_2, k_3, k_4]), 'target_y'] = 'rest'\n",
    "binary_subset.loc[df['target_y'].isin([i]), 'target_y'] = i\n",
    "k = 'rest'\n",
    "\n",
    "# Features\n",
    "X_binary = binary_subset.drop(['target_y'], axis=1)\n",
    "# Target\n",
    "y_binary = binary_subset['target_y']\n",
    "# Convert to 0 and 1 - i = 1, k = 0\n",
    "y_binary = (y_binary == i).astype('uint8')\n",
    "\n",
    "# Save train test sets\n",
    "dump(X_binary, str(i) + '_' + str(k) + '_X_binary.joblib')\n",
    "dump(y_binary, str(i) + '_' + str(k) + '_y_binary.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('First Label: ', i)\n",
    "#print('Second Label: ',k)\n",
    "print('Second Label: ' + k_1 + ', ' + k_2 + ', ' + k_3 + ', ' + k_4)\n",
    "print('Collectively: ', k)\n",
    "# Evaluate model accuracy - OVR clf\n",
    "# Averaged accuracy scores and standard deviations for each combination\n",
    "avg_accuracy_ovr = []\n",
    "avg_std_ovr = []\n",
    "avg_balanced_ovr = []\n",
    "avg_balanced_std_ovr = []\n",
    "# Classification metrics for each combination\n",
    "accuracy_ovr = []\n",
    "balanced_ovr = []\n",
    "\n",
    "# Track timestamp - elapsed time\n",
    "start_time = time.time()\n",
    "\n",
    "for n in range(X_binary.shape[1]):\n",
    "    # One Feature Classification using DecisionTree Classifier\n",
    "    binary_1Feature = pd.DataFrame(X_binary.iloc[:, n].values.reshape(-1, 1))\n",
    "    balanced_scores, accuracy_scores, _, _, _, _ = model_eval(binary_1Feature, y_binary,\n",
    "                                                              dt_model_binary, cv_binary)\n",
    "    # Store clf metrics\n",
    "    avg_accuracy_ovr.append(np.mean(accuracy_scores) * 100)\n",
    "    avg_std_ovr.append(np.std(accuracy_scores) * 100)\n",
    "    avg_balanced_ovr.append(np.mean(balanced_scores) * 100)\n",
    "    avg_balanced_std_ovr.append(np.std(balanced_scores) * 100)\n",
    "    # Store more clf metrics\n",
    "    accuracy_ovr.append(accuracy_scores)\n",
    "    balanced_ovr.append(balanced_scores)\n",
    "\n",
    "# Plot and Save Accuracy vs. Wavelengths\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Set colors\n",
    "ax.set_prop_cycle('color', cm.Spectral(np.linspace(0, 1, 11)))\n",
    "# Plot\n",
    "plt.plot(col_wavelengths, avg_accuracy_ovr)\n",
    "pos_std = np.array(avg_accuracy_ovr) + np.array(avg_std_ovr)\n",
    "neg_std = np.array(avg_accuracy_ovr) - np.array(avg_std_ovr)\n",
    "ax.fill_between(col_wavelengths, neg_std, pos_std, alpha=0.2)\n",
    "# Set figure object\n",
    "ax.set_title('Accuracy of ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('Classification Accuracy (%)')\n",
    "ax.xaxis.set_ticks(np.arange(400, 1850, 100))\n",
    "ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.2, -0.36], [10.3, 8.56]])\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_clf_accuracy.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_clf_accuracy.png', dpi=1080, bbox_inches=bbox)\n",
    "f.clear()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close('all')\n",
    "plt.close()\n",
    "\n",
    "# Plot and Save Balanced Accuracy vs. Wavelengths\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Set colors\n",
    "ax.set_prop_cycle('color', cm.Spectral(np.linspace(0, 1, 11)))\n",
    "# Plot\n",
    "plt.plot(col_wavelengths, avg_balanced_ovr)\n",
    "pos_std = np.array(avg_balanced_ovr) + np.array(avg_balanced_std_ovr)\n",
    "neg_std = np.array(avg_balanced_ovr) - np.array(avg_balanced_std_ovr)\n",
    "ax.fill_between(col_wavelengths, neg_std, pos_std, alpha=0.2)\n",
    "# Set figure object\n",
    "ax.set_title('Balanced Accuracy of ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('Balanced Classification Accuracy (%)')\n",
    "ax.xaxis.set_ticks(np.arange(400, 1850, 100))\n",
    "ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.2, -0.36], [10.3, 8.56]])\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_balanced_clf_accuracy.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_balanced_clf_accuracy.png', dpi=1080, bbox_inches=bbox)\n",
    "f.clear()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close('all')\n",
    "plt.close()\n",
    "\n",
    "# End timestamp\n",
    "end_time = time.time()\n",
    "print('Time to run: ', end_time - start_time, ' seconds')\n",
    "total_time.append(end_time - start_time)\n",
    "print('\\n')\n",
    "\n",
    "# Save result variables\n",
    "dump(avg_accuracy_ovr, str(i) + '_' + str(k) + '_avg_accuracy_ovr.joblib')\n",
    "dump(avg_std_ovr, str(i) + '_' + str(k) + '_avg_std_ovr.joblib')\n",
    "dump(avg_balanced_ovr, str(i) + '_' + str(k) + '_avg_balanced_ovr.joblib')\n",
    "dump(avg_balanced_std_ovr, str(i) + '_' + str(k) + '_avg_balanced_std_ovr.joblib')\n",
    "dump(accuracy_ovr, str(i) + '_' + str(k) + '_accuracy_ovr.joblib')\n",
    "dump(balanced_ovr, str(i) + '_' + str(k) + '_balanced_ovr.joblib')\n",
    "dump(total_time, str(i) + '_' + str(k) + '_total_time_ovr.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}