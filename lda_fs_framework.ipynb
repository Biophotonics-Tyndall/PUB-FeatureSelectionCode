{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Discriminative Analysis (LDA) Feature Selection (FS) Framework"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import matplotlib.transforms\n",
    "import matplotlib\n",
    "\n",
    "import time\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Disable Print\n",
    "def blockPrint():\n",
    "    sys.__stdout__ = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore Print\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to data directory\n",
    "\n",
    "work_path = os.getcwd()\n",
    "print(work_path)\n",
    "\n",
    "os.chdir('YOUR DATA DIRECTORY')\n",
    "data_path = os.getcwd()\n",
    "print(data_path)\n",
    "os.chdir(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "os.chdir(data_path)\n",
    "\n",
    "# Load dataset - df\n",
    "df = pd.read_csv('YOUR DATA FILE.csv')\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_by_y = df.groupby(['target_y']).mean()\n",
    "stdev_df_by_y = df.groupby(['target_y']).std()\n",
    "\n",
    "# Column names to numerical\n",
    "col_wavelengths = df.columns.drop('target_y')\n",
    "col_wavelengths = col_wavelengths.astype(np.float64)\n",
    "print('Number of wavelengths: ', len(col_wavelengths))\n",
    "\n",
    "# Legend labels\n",
    "tissue_types = df['target_y'].unique()\n",
    "tissue_types.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SG Smoothing of the raw data - Gentle smoothing with w/p = 2.5 to get rid of some baseline noise\n",
    "\n",
    "# Features\n",
    "X_raw = df.drop(['target_y'], axis=1)\n",
    "\n",
    "# Target\n",
    "y = df['target_y']\n",
    "\n",
    "# Spectral Smoothing - Savitzkyâ€“Golay (SG) method\n",
    "w = 5\n",
    "p = 2\n",
    "X_smooth = savgol_filter(X_raw, w, polyorder=p, axis=1, deriv=0)\n",
    "\n",
    "# Smoothed dataframe\n",
    "df_smooth = pd.DataFrame(X_smooth, columns = col_wavelengths.astype(\"string\"))\n",
    "df_smooth = pd.concat([df_smooth, y.rename('target_y')], axis=1)\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_by_y_smooth = df_smooth.groupby(['target_y']).mean()\n",
    "stdev_df_by_y_smooth = df_smooth.groupby(['target_y']).std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save path\n",
    "os.chdir(work_path)\n",
    "os.chdir('YOUR SAVE PATH')\n",
    "save_path = os.getcwd()\n",
    "print(save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to set intervals by indexing\n",
    "\n",
    "def interval_indexing(ind_list, interval_len):\n",
    "    return [ind_list[i:i+interval_len] for i in range(0, len(ind_list), interval_len)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to evaluate clf accuracy using lda - Number of Features is a variable\n",
    "# F1 score calculation can be added here\n",
    "\n",
    "def clf_accuracy_eval(X, y, model, cv):\n",
    "\n",
    "    # Initiate empty lists\n",
    "    clf_accuracy_scores = [] # Calculate classification scores\n",
    "    clf_balanced_scores = [] # Calculate balanced classification scores\n",
    "    #clf_f1_scores = [] # Calculate F1 scores\n",
    "    #count = 0\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # count+=1\n",
    "        # print(count, \" of \",  cv.get_n_splits(), \" CV folds \", end=\"\\r\")\n",
    "\n",
    "        # define model\n",
    "        clf_model = model # model needs to be refined in each loop? so move down into the loop?\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Fit model\n",
    "        clf_model.fit(X_train, y_train)\n",
    "        # Predict using the fitted model\n",
    "        y_predict = clf_model.predict(X_test)\n",
    "        # Calculate classification accuracy score\n",
    "        clf_score = accuracy_score(y_test, y_predict)\n",
    "        # Calculate classification balanced accuracy score\n",
    "        clf_balanced_score = balanced_accuracy_score(y_test, y_predict)\n",
    "        # Calculate classification F-1 score\n",
    "        #clf_f1_score = f1_score(y_test, y_predict, average='binary')\n",
    "        # Store each iteration\n",
    "        clf_accuracy_scores.append(clf_score)\n",
    "        clf_balanced_scores.append(clf_balanced_score)\n",
    "        #clf_f1_scores.append(clf_f1_score)\n",
    "\n",
    "    return clf_accuracy_scores, clf_balanced_scores #, clf_f1_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define temperature in Simulated Annealing\n",
    "\n",
    "def temperature_sa(accuracy_max): #-> need to fix this so that as accuracy increases, change of acceptance decreases\n",
    "    return 0.05 * (1-accuracy_max) + 0.00000001 # regularization term to avoid dividing by 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to optimize the final feature selection using Simulated Annealing\n",
    "\n",
    "def wv_sa_opt(X_select, y, cv, nwv_total, nwv_select, n_iter):\n",
    "\n",
    "    # Set the number of selected wavelength\n",
    "    nwv_total = nwv_total\n",
    "    nwv_select = nwv_select\n",
    "\n",
    "    # Set selected wv's - Initial condition is random shuffle\n",
    "    idx_wv_arr = np.arange(nwv_total)\n",
    "    np.random.shuffle(idx_wv_arr)\n",
    "    wv_select = idx_wv_arr[:nwv_select]\n",
    "    wv_exclude = idx_wv_arr[nwv_select:]\n",
    "\n",
    "    # Choose the selected wv's from the original X dataset\n",
    "    X_select_init = X_select[:,wv_select]\n",
    "\n",
    "    # Initialize list for storing updated clf accuracy from each iteration\n",
    "    all_clf_accuracy = []\n",
    "    all_wv_select = []\n",
    "    all_wv_exclude = []\n",
    "\n",
    "    # Calculate the initial clf accuracy score using the randomly selected wv's - LDA for clf\n",
    "    # define lda regression\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    # Simple cv score\n",
    "    lda_scores = cross_val_score(lda, X_select_init, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    lda_score_init = np.mean(lda_scores)\n",
    "    # Store initial conditions\n",
    "    all_clf_accuracy.append(lda_score_init)\n",
    "    all_wv_select.append(wv_select)\n",
    "    all_wv_exclude.append(wv_exclude)\n",
    "    print('The initial clf accuracy using LDA: %.5f ' % lda_score_init)\n",
    "\n",
    "    # Simulated Annealing loop\n",
    "\n",
    "    # Initialize arrays for updating\n",
    "    wv_select_update = np.copy(wv_select)\n",
    "    print('Initial Selected wv', wv_select_update)\n",
    "    wv_exclude_update = np.copy(wv_exclude)\n",
    "    print('Initial Excluded wv', wv_exclude_update)\n",
    "    lda_score_update = lda_score_init\n",
    "\n",
    "    if lda_score_init == 1:\n",
    "        print('-> LDA clf accuracy is already 100%')\n",
    "        wv_select_update = wv_select_update\n",
    "        lda_score_update = lda_score_update\n",
    "        update_count = 0\n",
    "        all_clf_accuracy = []\n",
    "        all_wv_select = []\n",
    "        all_wv_exclude = []\n",
    "    else:\n",
    "\n",
    "        update_count = 0\n",
    "\n",
    "        for i in range(n_iter):\n",
    "\n",
    "            print('\\n')\n",
    "            print('--- Iteration: ', i, ' ---')\n",
    "            # Define temperature reg\n",
    "            temp_reg = temperature_sa(lda_score_update)\n",
    "            print('Temperature Reg for SA: ', temp_reg)\n",
    "            # Initialize lists for updates in the inner loop\n",
    "            wv_select_inner = np.copy(wv_select_update)\n",
    "            wv_exclude_inner = np.copy(wv_exclude_update)\n",
    "\n",
    "            # Change one element during each iteration\n",
    "            idx_select = np.random.randint(nwv_select)\n",
    "            idx_exclude = np.random.randint(nwv_total-nwv_select)\n",
    "            item_select = wv_select_inner[idx_select]\n",
    "            print('Selected wv for Exchange: ', item_select)\n",
    "            item_exclude = wv_exclude_inner[idx_exclude]\n",
    "            print('Excluded PC for Exchange: ', item_exclude)\n",
    "            wv_select_inner[idx_select] = item_exclude\n",
    "            print('New Selected PCs: ', wv_select_inner)\n",
    "            wv_exclude_inner[idx_exclude] = item_select\n",
    "            print('New Excluded PCs: ', wv_exclude_inner)\n",
    "\n",
    "            # Select the new PCs and evaluate\n",
    "            X_select_update = X_select[:,wv_select_inner]\n",
    "            # define lda regression\n",
    "            lda_inner = LinearDiscriminantAnalysis()\n",
    "            # Simple cv score\n",
    "            lda_scores_inner = cross_val_score(lda_inner, X_select_update, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "            lda_score_inner = np.mean(lda_scores_inner)\n",
    "            print('Update clf accuracy: %.5f ' % lda_score_inner)\n",
    "            print('Old clf accuracy: %.5f ' % lda_score_update)\n",
    "\n",
    "\n",
    "            # Make decision\n",
    "            if lda_score_inner > lda_score_update:\n",
    "                print('-> Yes higher clf accuracy')\n",
    "                # Update\n",
    "                wv_select_update = wv_select_inner\n",
    "                wv_exclude_update = wv_exclude_inner\n",
    "                lda_score_update = lda_score_inner\n",
    "                update_count += 1\n",
    "                print('-> Number of updates: ', update_count)\n",
    "                # Store\n",
    "                all_clf_accuracy.append(lda_score_update)\n",
    "                all_wv_select.append(wv_select_update)\n",
    "                all_wv_exclude.append(wv_exclude_update)\n",
    "                print('-> New wv: ', wv_select_update)\n",
    "                print('-> New clf accuracy: %.5f ' % lda_score_update)\n",
    "            elif lda_score_inner <= lda_score_update:\n",
    "                sa_prob = np.exp((lda_score_inner-lda_score_update)/temp_reg)\n",
    "                print('SA Probability: ', sa_prob)\n",
    "                if np.random.random() < sa_prob:\n",
    "                    print('-> Accepted; Lower than SA probability')\n",
    "                    # Update\n",
    "                    wv_select_update = wv_select_inner\n",
    "                    wv_exclude_update = wv_exclude_inner\n",
    "                    lda_score_update = lda_score_inner\n",
    "                    update_count += 1\n",
    "                    print('-> Number of updates: ', update_count)\n",
    "                    # Store\n",
    "                    all_clf_accuracy.append(lda_score_update)\n",
    "                    all_wv_select.append(wv_select_update)\n",
    "                    all_wv_exclude.append(wv_exclude_update)\n",
    "                    print('-> New wv: ', wv_select_update)\n",
    "                    print('-> New clf accuracy: %.5f ' % lda_score_update)\n",
    "                else:\n",
    "                    print('-> Rejected')\n",
    "                    print('-> Keep Old PCs: ', wv_select_update)\n",
    "                    print('-> Keep Old Accuracy: %.5f ' % lda_score_update)\n",
    "                    # Store\n",
    "                    all_clf_accuracy.append(lda_score_update)\n",
    "                    all_wv_select.append(wv_select_update)\n",
    "                    all_wv_exclude.append(wv_exclude_update)\n",
    "\n",
    "    return wv_select_update, lda_score_update, all_clf_accuracy, all_wv_select, all_wv_exclude, update_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The OVO Approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save path\n",
    "os.chdir(save_path)\n",
    "os.chdir('YOUR SAVE PATH - SUBFOLDER')\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LDA Framework for the OVO approach starts here:\n",
    "\n",
    "# Define parameters\n",
    "df_dataset = df_smooth\n",
    "tissue_types = tissue_types\n",
    "\n",
    "random_state = 42\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)\n",
    "\n",
    "# Define binary combinations\n",
    "list_tissue_comb = list(combinations(tissue_types,2))\n",
    "# Save the list of binary pairs\n",
    "if not os.path.exists('order_of_tissue_comb.joblib'):\n",
    "    dump(list_tissue_comb, 'order_of_tissue_comb.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run the for loop to calculate for all binary pairs\n",
    "\n",
    "# for i,k in combinations(tissue_types,2): # can separate this to make an individual function\n",
    "#\n",
    "#     # Track timestamp - elapsed time\n",
    "#     start_time = time.time()\n",
    "#\n",
    "#     count += 1\n",
    "\n",
    "    # if count == 2:\n",
    "    #     print('count = 2; break')\n",
    "    #     break\n",
    "\n",
    "# Else for single pairs --->\n",
    "\n",
    "i = 'boneCement'\n",
    "k = 'cortBone'\n",
    "\n",
    "# i = 'boneMarrow'\n",
    "# k = 'cortBone'\n",
    "\n",
    "#print('Iteration: ', count)\n",
    "print('First Label: ', i)\n",
    "print('Second Label: ',k)\n",
    "\n",
    "# Data selection\n",
    "binary_subset = df_dataset.loc[(df['target_y'] == i) + (df['target_y'] == k)]\n",
    "\n",
    "# Features\n",
    "X_binary_init = binary_subset.drop(['target_y'], axis=1)\n",
    "# Target\n",
    "y_binary_init = binary_subset['target_y']\n",
    "# Convert to 0 and 1 - i = 1, k = 0\n",
    "y_binary_init = (y_binary_init == i).astype('uint8')\n",
    "\n",
    "# Split Train Test Validation set\n",
    "X_binary, X_val_all, y_binary, y_val_all = train_test_split(X_binary_init, y_binary_init,\n",
    "                                                            test_size=0.2, stratify=y_binary_init, random_state=random_state)\n",
    "# Save train test sets\n",
    "dump(X_binary, str(i) + '_' + str(k) + '_X_binary.joblib')\n",
    "dump(X_val_all, str(i) + '_' + str(k) + '_X_val_all.joblib')\n",
    "dump(y_binary, str(i) + '_' + str(k) + '_y_binary.joblib')\n",
    "dump(y_val_all, str(i) + '_' + str(k) + '_y_val_all.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Moving-window approach to select features using LDA coeff ranking\n",
    "win_size = [25, 50, 75, 100, 150, 200, 300]\n",
    "wv_idx = np.arange(0, len(col_wavelengths),1)\n",
    "all_selected_wv = []\n",
    "for win in win_size:\n",
    "    print('Window Size: ', win)\n",
    "\n",
    "    # Set interval indices\n",
    "    wv_idx_interval = interval_indexing(wv_idx, interval_len=win)\n",
    "    print('Number of Intervals: ', len(wv_idx_interval))\n",
    "\n",
    "    win_selected_wv = []\n",
    "    for interval in range(len(wv_idx_interval)):\n",
    "\n",
    "        # Define feature selection model - LDA\n",
    "        lda_fs_model = LinearDiscriminantAnalysis()\n",
    "        # Selector\n",
    "        fs_selector = SelectFromModel(lda_fs_model, max_features=1).fit(X_binary.iloc[:, wv_idx_interval[interval]],y_binary)\n",
    "        # Wavelength interval\n",
    "        wv_interval = col_wavelengths[wv_idx_interval[interval]]\n",
    "        selected_wv = wv_interval[fs_selector.get_support()]\n",
    "        win_selected_wv.append(selected_wv[0])\n",
    "    all_selected_wv.append(win_selected_wv)\n",
    "\n",
    "# Remove duplicates and wavelengths separated by <= 30nm\n",
    "all_selected_wv = [wv for sublist in all_selected_wv for wv in sublist]\n",
    "all_selected_wv=list(dict.fromkeys(all_selected_wv))\n",
    "pt_dup = []\n",
    "for x, y in combinations(all_selected_wv,2):\n",
    "    if abs(x-y)<=20:\n",
    "        ind = np.where(all_selected_wv==y)[0][0]\n",
    "        pt_dup.append(ind)\n",
    "# Remove duplicated indices\n",
    "pt_dup = np.unique(pt_dup)\n",
    "# Remove the peaks\n",
    "if np.any(pt_dup):\n",
    "    all_selected_wv_final = np.delete(all_selected_wv, pt_dup)\n",
    "else:\n",
    "    all_selected_wv_final = all_selected_wv\n",
    "\n",
    "# Convert to str\n",
    "all_selected_wv_final_str = [str(x) for x in all_selected_wv_final]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the number of features to be selected for SA\n",
    "fraction = 0.75\n",
    "K_features = math.floor(len(all_selected_wv_final) * fraction)\n",
    "print('The number of features to be selected: ', K_features)\n",
    "\n",
    "# Define estimator\n",
    "fs_model = LinearDiscriminantAnalysis()\n",
    "# Define feature selection model - LDA\n",
    "fs = SelectFromModel(fs_model).fit(X_binary.loc[:, all_selected_wv_final_str], y_binary)\n",
    "\n",
    "# Find the index from high to low\n",
    "fs_coeff_ind = np.argsort(-abs(fs.estimator_.coef_)).T\n",
    "\n",
    "# Initiate the search\n",
    "selected_ind_update = [fs_coeff_ind[0][0]]\n",
    "fs_coeff_ind_update = np.copy(fs_coeff_ind)\n",
    "fs_coeff_ind_update = np.delete(fs_coeff_ind_update, 0)\n",
    "\n",
    "while len(selected_ind_update) < K_features:\n",
    "    #print('Number of Selected Ind: ', len(selected_ind_update))\n",
    "    pearson_rank = []\n",
    "    for n in range(len(fs_coeff_ind_update)):\n",
    "        pearson_corr = np.max(\n",
    "            np.abs(np.corrcoef(X_binary.iloc[:, selected_ind_update + [fs_coeff_ind_update[n]]], rowvar=False))\n",
    "            - np.identity(len(selected_ind_update) + 1))\n",
    "        pearson_rank.append(pearson_corr)\n",
    "    selected_ind = np.argsort(pearson_rank)[0]\n",
    "    selected_fs_coeff_ind = fs_coeff_ind_update[selected_ind]\n",
    "    #print('Selected Ind: ', selected_anova_ind)\n",
    "    #print('Selected Pearson Coeff: ', pearson_rank[selected_ind])\n",
    "    selected_ind_update.append(selected_fs_coeff_ind)\n",
    "    fs_coeff_ind_update = np.delete(fs_coeff_ind_update, selected_ind)\n",
    "\n",
    "# Find the final selected wavelengths\n",
    "lda_select_wv_final_str = pd.Series(all_selected_wv_final_str)[selected_ind_update]\n",
    "lda_select_wv_final = pd.Series(all_selected_wv_final)[selected_ind_update]\n",
    "dump(lda_select_wv_final, str(i) + '_' + str(k) + '_LDA_select_wv.joblib')\n",
    "\n",
    "# SA to select the 10 features that give the highest LDA clf accuracy\n",
    "lda_select_wv_1 = X_binary.loc[:, lda_select_wv_final_str].values\n",
    "lda_sa_fs_wv,aa,bb,cc,dd,ee = wv_sa_opt(lda_select_wv_1, y_binary, cv=10, nwv_total=len(lda_select_wv_final), nwv_select=10, n_iter = 2000)\n",
    "\n",
    "# The final 10 features\n",
    "lda_sa_fs_wv_10 = lda_select_wv_final.iloc[lda_sa_fs_wv]\n",
    "lda_sa_fs_wv_10_str = [str(x) for x in lda_sa_fs_wv_10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot and save selected wavelengths on spectra\n",
    "# Set custom color cycle\n",
    "custom_cycler = (cycler('color', ['#d62728', '#1f77b4', '#2ca02c', '#ff7f0e',\n",
    "                                  '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']) +\n",
    "                 cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_select_tissues = binary_subset.groupby(['target_y']).mean()\n",
    "stdev_df_select_tissues = binary_subset.groupby(['target_y']).std()\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Set colors\n",
    "ax.set_prop_cycle(custom_cycler)\n",
    "# Plot\n",
    "select_tissue_label = [i,k]\n",
    "for tissue in range(avg_df_select_tissues.shape[0]):\n",
    "    plt.plot(col_wavelengths, avg_df_select_tissues.iloc[tissue,:], label = select_tissue_label[tissue])\n",
    "    pos_std = avg_df_select_tissues.iloc[tissue,:] + stdev_df_select_tissues.iloc[tissue,:]\n",
    "    neg_std = avg_df_select_tissues.iloc[tissue,:] - stdev_df_select_tissues.iloc[tissue,:]\n",
    "    ax.fill_between(col_wavelengths, neg_std, pos_std, alpha = 0.08)\n",
    "for wv in lda_sa_fs_wv_10:\n",
    "    plt.axvline(x=wv, color='#2ca02c', linestyle='-', alpha=0.6, lw=1.75)\n",
    "# Add text - selected wavelengths\n",
    "plt.text(0, -0.12, 'Final Selected Wavelength: '+ str(np.array(lda_sa_fs_wv_10)),\n",
    "         horizontalalignment='left', verticalalignment = 'center_baseline', transform=ax.transAxes)\n",
    "# Set figure object\n",
    "ax.set_title('Selected Peaks for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('Normalized Intensity (A.U.)')\n",
    "ax.set_xlim([350, 1850])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "bbox = matplotlib.transforms.Bbox([[-0.45, -1.3], [11.45, 8.56]])\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_LDA_select_wv.png'):\n",
    "    f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_LDA_select_wv.png', dpi = 1080, bbox_inches =bbox)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The OVR Approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save_path\n",
    "os.chdir(save_path)\n",
    "os.chdir('YOUR SAVE PATH - SUBFOLDER')\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "df_dataset = df_smooth\n",
    "\n",
    "# Tissue labels\n",
    "tissue_types = tissue_types\n",
    "\n",
    "# Set global random state\n",
    "random_state = 42\n",
    "\n",
    "# Define cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One vs Rest\n",
    "\n",
    "# Bone Cement = 1 vs. [Cortical Bone, Trabecular Bone, Cartilage, Bone Marrow] = 0\n",
    "i = 'boneCement'\n",
    "k_1 = 'cortBone'\n",
    "k_2 = 'traBone'\n",
    "k_3 = 'cartilage'\n",
    "k_4 = 'boneMarrow'\n",
    "\n",
    "# Cortical Bone = 1 vs. [Trabecular Bone, Cartilage, Bone Marrow, Muscle] = 0\n",
    "# i = 'cortBone'\n",
    "# k_1 = 'traBone'\n",
    "# k_2 = 'muscle'\n",
    "# k_3 = 'cartilage'\n",
    "# k_4 = 'boneMarrow'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('First Label: ', i)\n",
    "#print('Second Label: ',k)\n",
    "print('Second Label: ' + k_1 + ', ' + k_2 + ', ' + k_3 + ', ' + k_4)\n",
    "\n",
    "# Data selection for multiple tissue types\n",
    "df_subset = df_dataset[df_dataset['target_y'].isin([i,k_1,k_2,k_3,k_4])]\n",
    "binary_subset = df_dataset[df_dataset['target_y'].isin([i,k_1,k_2,k_3,k_4])]\n",
    "binary_subset.loc[df['target_y'].isin([k_1, k_2, k_3, k_4]), 'target_y'] = 'rest'\n",
    "binary_subset.loc[df['target_y'].isin([i]), 'target_y'] = i\n",
    "k = 'rest'\n",
    "\n",
    "# Features\n",
    "X_binary_init = binary_subset.drop(['target_y'], axis=1)\n",
    "# Target\n",
    "y_binary_init = binary_subset['target_y']\n",
    "# Convert to 0 and 1 - i = 1, k = 0\n",
    "y_binary_init = (y_binary_init == i).astype('uint8')\n",
    "\n",
    "# Split Train Test Validation set\n",
    "X_binary, X_val_all, y_binary, y_val_all = train_test_split(X_binary_init, y_binary_init,\n",
    "                                                            test_size=0.2, stratify=y_binary_init, random_state=random_state)\n",
    "\n",
    "# Save train test sets\n",
    "dump(X_binary, str(i) + '_' + str(k) + '_X_binary.joblib')\n",
    "dump(X_val_all, str(i) + '_' + str(k) + '_X_val_all.joblib')\n",
    "dump(y_binary, str(i) + '_' + str(k) + '_y_binary.joblib')\n",
    "dump(y_val_all, str(i) + '_' + str(k) + '_y_val_all.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('First Label: ', i)\n",
    "#print('Second Label: ',k)\n",
    "print('Second Label: ' + k_1 + ', ' + k_2 + ', ' + k_3 + ', ' + k_4)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Moving-window approach to select features using LDA coeff ranking\n",
    "win_size = [25, 50, 75, 100, 150, 200, 300]\n",
    "wv_idx = np.arange(0, len(col_wavelengths),1)\n",
    "all_selected_wv = []\n",
    "for win in win_size:\n",
    "    print('Window Size: ', win)\n",
    "\n",
    "    # Set interval indices\n",
    "    wv_idx_interval = interval_indexing(wv_idx, interval_len=win)\n",
    "    print('Number of Intervals: ', len(wv_idx_interval))\n",
    "\n",
    "    win_selected_wv = []\n",
    "    for interval in range(len(wv_idx_interval)):\n",
    "\n",
    "        # Define feature selection model - LDA\n",
    "        lda_fs_model = LinearDiscriminantAnalysis()\n",
    "        # Selector\n",
    "        fs_selector = SelectFromModel(lda_fs_model, max_features=1).fit(X_binary.iloc[:, wv_idx_interval[interval]],y_binary)\n",
    "        # Wavelength interval\n",
    "        wv_interval = col_wavelengths[wv_idx_interval[interval]]\n",
    "        selected_wv = wv_interval[fs_selector.get_support()]\n",
    "        win_selected_wv.append(selected_wv[0])\n",
    "    all_selected_wv.append(win_selected_wv)\n",
    "\n",
    "# Remove duplicates and wavelengths separated by <= 20nm\n",
    "all_selected_wv = [wv for sublist in all_selected_wv for wv in sublist]\n",
    "all_selected_wv=list(dict.fromkeys(all_selected_wv))\n",
    "pt_dup = []\n",
    "for x, y in combinations(all_selected_wv,2):\n",
    "    if abs(x-y)<=20:\n",
    "        ind = np.where(all_selected_wv==y)[0][0]\n",
    "        pt_dup.append(ind)\n",
    "# Remove duplicated indices\n",
    "pt_dup = np.unique(pt_dup)\n",
    "# Remove the peaks\n",
    "if np.any(pt_dup):\n",
    "    all_selected_wv_final = np.delete(all_selected_wv, pt_dup)\n",
    "else:\n",
    "    all_selected_wv_final = all_selected_wv\n",
    "\n",
    "# Convert to str\n",
    "all_selected_wv_final_str = [str(x) for x in all_selected_wv_final]\n",
    "\n",
    "# Define the number of features to be selected for SA\n",
    "fraction = 0.75\n",
    "K_features = math.floor(len(all_selected_wv_final) * fraction)\n",
    "print('The number of features to be selected: ', K_features)\n",
    "# Define estimator\n",
    "fs_model = LinearDiscriminantAnalysis()\n",
    "# Define feature selection model - LDA\n",
    "fs = SelectFromModel(fs_model).fit(X_binary.loc[:, all_selected_wv_final_str], y_binary)\n",
    "\n",
    "# Find the index from high to low\n",
    "fs_coeff_ind = np.argsort(-abs(fs.estimator_.coef_)).T\n",
    "\n",
    "# Initiate the search\n",
    "selected_ind_update = [fs_coeff_ind[0][0]]\n",
    "fs_coeff_ind_update = np.copy(fs_coeff_ind)\n",
    "fs_coeff_ind_update = np.delete(fs_coeff_ind_update, 0)\n",
    "\n",
    "while len(selected_ind_update) < K_features:\n",
    "    #print('Number of Selected Ind: ', len(selected_ind_update))\n",
    "    pearson_rank = []\n",
    "    for n in range(len(fs_coeff_ind_update)):\n",
    "        pearson_corr = np.max(\n",
    "            np.abs(np.corrcoef(X_binary.iloc[:, selected_ind_update + [fs_coeff_ind_update[n]]], rowvar=False))\n",
    "            - np.identity(len(selected_ind_update) + 1))\n",
    "        pearson_rank.append(pearson_corr)\n",
    "    selected_ind = np.argsort(pearson_rank)[0]\n",
    "    selected_fs_coeff_ind = fs_coeff_ind_update[selected_ind]\n",
    "    #print('Selected Ind: ', selected_anova_ind)\n",
    "    #print('Selected Pearson Coeff: ', pearson_rank[selected_ind])\n",
    "    selected_ind_update.append(selected_fs_coeff_ind)\n",
    "    fs_coeff_ind_update = np.delete(fs_coeff_ind_update, selected_ind)\n",
    "\n",
    "# Find the final selected wavelengths\n",
    "lda_select_wv_final_str = pd.Series(all_selected_wv_final_str)[selected_ind_update]\n",
    "lda_select_wv_final = pd.Series(all_selected_wv_final)[selected_ind_update]\n",
    "#dump(lda_select_wv_final, str(i) + '_' + str(k) + '_LDA_select_wv.joblib')\n",
    "# SA to select the 10 features that give the highest LDA clf accuracy\n",
    "lda_select_wv_1 = X_binary.loc[:, lda_select_wv_final_str].values\n",
    "lda_sa_fs_wv, aa, bb, cc, dd, ee = wv_sa_opt(lda_select_wv_1, y_binary, cv=10, nwv_total=len(lda_select_wv_final),\n",
    "                                             nwv_select=10, n_iter=2000)\n",
    "\n",
    "# The final 10 features\n",
    "lda_sa_fs_wv_10 = lda_select_wv_final.iloc[lda_sa_fs_wv]\n",
    "lda_sa_fs_wv_10_str = [str(x) for x in lda_sa_fs_wv_10]\n",
    "#dump(lda_sa_fs_wv_10, str(i) + '_' + str(k) + '_LDA_SA_select_wv_final.joblib')\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time to run: ', (end_time - start_time)/60, ' minutes')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the number of features to be selected with SA\n",
    "fraction = 0.75\n",
    "K_features = math.floor(len(all_selected_wv_final) * fraction)\n",
    "print('The number of features to be selected: ', K_features)\n",
    "\n",
    "# Define estimator\n",
    "fs_model = LinearDiscriminantAnalysis()\n",
    "# Define feature selection model - LDA\n",
    "fs = SelectFromModel(fs_model).fit(X_binary.loc[:, all_selected_wv_final_str], y_binary)\n",
    "\n",
    "# Find the index from high to low\n",
    "fs_coeff_ind = np.argsort(-abs(fs.estimator_.coef_)).T\n",
    "\n",
    "# Initiate the search\n",
    "selected_ind_update = [fs_coeff_ind[0][0]]\n",
    "fs_coeff_ind_update = np.copy(fs_coeff_ind)\n",
    "fs_coeff_ind_update = np.delete(fs_coeff_ind_update, 0)\n",
    "\n",
    "while len(selected_ind_update) < K_features:\n",
    "    #print('Number of Selected Ind: ', len(selected_ind_update))\n",
    "    pearson_rank = []\n",
    "    for n in range(len(fs_coeff_ind_update)):\n",
    "        pearson_corr = np.max(\n",
    "            np.abs(np.corrcoef(X_binary.iloc[:, selected_ind_update + [fs_coeff_ind_update[n]]], rowvar=False))\n",
    "            - np.identity(len(selected_ind_update) + 1))\n",
    "        pearson_rank.append(pearson_corr)\n",
    "    selected_ind = np.argsort(pearson_rank)[0]\n",
    "    selected_fs_coeff_ind = fs_coeff_ind_update[selected_ind]\n",
    "    #print('Selected Ind: ', selected_anova_ind)\n",
    "    #print('Selected Pearson Coeff: ', pearson_rank[selected_ind])\n",
    "    selected_ind_update.append(selected_fs_coeff_ind)\n",
    "    fs_coeff_ind_update = np.delete(fs_coeff_ind_update, selected_ind)\n",
    "\n",
    "# Find the final selected wavelengths\n",
    "lda_select_wv_final_str = pd.Series(all_selected_wv_final_str)[selected_ind_update]\n",
    "lda_select_wv_final = pd.Series(all_selected_wv_final)[selected_ind_update]\n",
    "\n",
    "# Save Variables\n",
    "dump(lda_select_wv_final, str(i) + '_' + str(k) + '_LDA_select_wv.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SA to select the 10 features that give the highest LDA clf accuracy\n",
    "lda_select_wv_1 = X_binary.loc[:, lda_select_wv_final_str].values\n",
    "lda_sa_fs_wv, aa, bb, cc, dd, ee = wv_sa_opt(lda_select_wv_1, y_binary, cv=10, nwv_total=len(lda_select_wv_final),\n",
    "                                             nwv_select=10, n_iter=2000)\n",
    "\n",
    "# The final 10 features\n",
    "lda_sa_fs_wv_10 = lda_select_wv_final.iloc[lda_sa_fs_wv]\n",
    "lda_sa_fs_wv_10_str = [str(x) for x in lda_sa_fs_wv_10]\n",
    "# Save\n",
    "dump(lda_sa_fs_wv_10, str(i) + '_' + str(k) + '_LDA_SA_select_wv_final.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot and save selected wavelengths on spectra\n",
    "# Set custom color cycle\n",
    "custom_cycler = (cycler('color', ['#d62728', '#1f77b4', '#2ca02c', '#ff7f0e',\n",
    "                                  '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']) +\n",
    "                 cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_select_tissues = df_subset.groupby(['target_y']).mean()\n",
    "stdev_df_select_tissues = df_subset.groupby(['target_y']).std()\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Plot\n",
    "select_tissue_label = [i,k_1,k_2,k_3,k_4]\n",
    "select_tissue_label.sort()\n",
    "# Set custom color cycle\n",
    "custom_cycler_boneCement = (cycler('color', ['#d62728', '#808080', '#808080', '#808080', '#808080']) +\n",
    "                            cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "# custom_cycler_cortBone = (cycler('color', ['#808080', '#808080', '#d62728', '#808080', '#808080']) +\n",
    "#                           cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "# Set colors\n",
    "ax.set_prop_cycle(custom_cycler_boneCement)\n",
    "#ax.set_prop_cycle(custom_cycler_cortBone)\n",
    "for tissue in range(avg_df_select_tissues.shape[0]):\n",
    "    plt.plot(col_wavelengths, avg_df_select_tissues.iloc[tissue, :], label=select_tissue_label[tissue])\n",
    "    pos_std = avg_df_select_tissues.iloc[tissue, :] + stdev_df_select_tissues.iloc[tissue, :]\n",
    "    neg_std = avg_df_select_tissues.iloc[tissue, :] - stdev_df_select_tissues.iloc[tissue, :]\n",
    "    ax.fill_between(col_wavelengths, neg_std, pos_std, alpha=0.08)\n",
    "for wv in lda_sa_fs_wv_10:\n",
    "    plt.axvline(x=wv, color='#2ca02c', linestyle='-', alpha=0.6, lw=1.75)\n",
    "# Add text - selected wavelengths\n",
    "plt.text(0, -0.12, 'Final Selected Wavelength: ' + str(np.array(lda_sa_fs_wv_10)),\n",
    "         horizontalalignment='left', verticalalignment='center_baseline', transform=ax.transAxes)\n",
    "# Set figure object\n",
    "ax.set_title('Selected Peaks for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('Normalized Intensity (A.U.)')\n",
    "ax.set_xlim([350, 1850])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "bbox = matplotlib.transforms.Bbox([[-0.45, -1.3], [11.45, 8.56]])\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_LDA_select_wv.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_LDA_select_wv.png', dpi=1080, bbox_inches=bbox)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Accuracy vs. Number of Features in the order given by the algorithm\n",
    "- or can rank the order by f_classif scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the final selected wavelengths\n",
    "lda_sa_fs_wv_10 = load('YOUR SELECTED WAVELENGTHS.joblib') # in float; or use the variable directly from above\n",
    "lda_sa_fs_wv_10_str = [str(x) for x in lda_sa_fs_wv_10] # convert to string if float\n",
    "print('Final wv:, ', lda_sa_fs_wv_10_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "df_dataset = df_smooth\n",
    "\n",
    "# Tissue types\n",
    "i = 'boneCement'\n",
    "k_1 = 'cortBone'\n",
    "k_2 = 'traBone'\n",
    "k_3 = 'cartilage'\n",
    "k_4 = 'boneMarrow'\n",
    "\n",
    "# i = 'cortBone'\n",
    "# k_1 = 'traBone'\n",
    "# k_2 = 'muscle'\n",
    "# k_3 = 'cartilage'\n",
    "# k_4 = 'boneMarrow'\n",
    "\n",
    "k = 'rest'\n",
    "\n",
    "# Select from the original dataset\n",
    "#df_subset = df_dataset[df_dataset['target_y'].isin([i,k_1,k_2,k_3,k_4])]\n",
    "\n",
    "# Features - Bone Cement\n",
    "X_binary = load('boneCement_rest_X_binary.joblib') # train/test\n",
    "X_val = load('boneCement_rest_X_val_all.joblib') # validation\n",
    "# Target\n",
    "y_binary = load('boneCement_rest_y_binary.joblib') # train/test\n",
    "y_val = load('boneCement_rest_y_val_all.joblib') # validation\n",
    "\n",
    "# Features - Cortical Bone\n",
    "# X_binary = load('cortBone_rest_X_binary.joblib') # train/test\n",
    "# X_val = load('cortBone_rest_X_val_all.joblib') # validation\n",
    "# # Target\n",
    "# y_binary = load('cortBone_rest_y_binary.joblib') # train/test\n",
    "# y_val = load('cortBone_rest_y_val_all.joblib') # validation\n",
    "\n",
    "# Select the features\n",
    "lda_select_X_binary = X_binary.loc[:, lda_sa_fs_wv_10]\n",
    "lda_select_X_val = X_val_all.loc[:, lda_sa_fs_wv_10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate clf accuracy\n",
    "\n",
    "all_lda_scores = []\n",
    "all_lda_stdev = []\n",
    "all_lda_scores_val = []\n",
    "all_lda_stdev_val = []\n",
    "\n",
    "all_lda_balanced_scores = []\n",
    "all_lda_balanced_stdev = []\n",
    "all_lda_balanced_scores_val = []\n",
    "all_lda_balanced_stdev_val = []\n",
    "for wv in range(len(lda_sa_fs_wv_10)):\n",
    "    # Define LDA model\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # Calculate clf accuracy cv\n",
    "    print('Number of Features: ', wv + 1)\n",
    "    lda_cv_scores, lda_balanced_scores = clf_accuracy_eval(lda_select_X_binary.iloc[:, 0:wv + 1], y_binary, model, cv)\n",
    "    lda_cv_scores_val, lda_balanced_scores_val = clf_accuracy_eval(lda_select_X_val.iloc[:, 0:wv + 1], y_val_all, model, cv)\n",
    "\n",
    "    all_lda_scores.append(np.mean(lda_cv_scores))\n",
    "    all_lda_stdev.append(np.std(lda_cv_scores))\n",
    "    all_lda_balanced_scores.append(np.mean(lda_balanced_scores))\n",
    "    all_lda_balanced_stdev.append(np.std(lda_balanced_scores))\n",
    "\n",
    "    all_lda_scores_val.append(np.mean(lda_cv_scores_val))\n",
    "    all_lda_stdev_val.append(np.std(lda_cv_scores_val))\n",
    "    all_lda_balanced_scores_val.append(np.mean(lda_balanced_scores_val))\n",
    "    all_lda_balanced_stdev_val.append(np.std(lda_balanced_scores_val))\n",
    "\n",
    "# Save\n",
    "dump(all_lda_scores, str(i) + '_' + str(k) + '_LDA_accuracy_nFeatures_train_new.joblib')\n",
    "dump(all_lda_stdev, str(i) + '_' + str(k) + '_LDA_stdev_nFeatures_train_new.joblib')\n",
    "dump(all_lda_balanced_scores, str(i) + '_' + str(k) + '_LDA_balanced_nFeatures_train_new.joblib')\n",
    "dump(all_lda_balanced_stdev, str(i) + '_' + str(k) + '_LDA_balanced_stdev_nFeatures_train_new.joblib')\n",
    "\n",
    "dump(all_lda_scores_val, str(i) + '_' + str(k) + '_LDA_accuracy_nFeatures_val_new.joblib')\n",
    "dump(all_lda_stdev_val, str(i) + '_' + str(k) + '_LDA_stdev_nFeatures_val_new.joblib')\n",
    "dump(all_lda_balanced_scores_val, str(i) + '_' + str(k) + '_LDA_balanced_nFeatures_val_new.joblib')\n",
    "dump(all_lda_balanced_stdev_val, str(i) + '_' + str(k) + '_LDA_balanced_stdev_nFeatures_val_new.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Accuracy on train\n",
    "plt.plot(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_scores, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_scores, yerr=all_lda_stdev,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + lda_sa_fs_wv_10_str\n",
    "plt.xticks(np.arange(0, len(lda_sa_fs_wv_10) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_LDA_accuracy_nFeatures_train.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_LDA_accuracy_nFeatures_train.png', dpi=1080,\n",
    "              bbox_inches=bbox)\n",
    "\n",
    "\n",
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Balanced accuracy on train\n",
    "plt.plot(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_balanced_scores, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_balanced_scores,\n",
    "             yerr=all_lda_balanced_stdev,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + lda_sa_fs_wv_10_str\n",
    "plt.xticks(np.arange(0, len(lda_sa_fs_wv_10) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_LDA_balanced_nFeatures_train.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_LDA_balanced_nFeatures_train.png', dpi=1080,\n",
    "              bbox_inches=bbox)\n",
    "\n",
    "\n",
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Accuracy on validation\n",
    "plt.plot(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_scores_val, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_scores_val, yerr=all_lda_stdev_val,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + lda_sa_fs_wv_10_str\n",
    "plt.xticks(np.arange(0, len(lda_sa_fs_wv_10) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_LDA_accuracy_nFeatures_val.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_LDA_accuracy_nFeatures_val.png', dpi=1080,\n",
    "              bbox_inches=bbox)\n",
    "\n",
    "\n",
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Balanced accuracy on validation\n",
    "plt.plot(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_balanced_scores_val, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(lda_sa_fs_wv_10), len(lda_sa_fs_wv_10)), all_lda_balanced_scores_val,\n",
    "             yerr=all_lda_balanced_stdev_val,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + lda_sa_fs_wv_10_str\n",
    "plt.xticks(np.arange(0, len(lda_sa_fs_wv_10) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_LDA_balanced_nFeatures_val.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_LDA_balanced_nFeatures_val.png', dpi=1080,\n",
    "              bbox_inches=bbox)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}