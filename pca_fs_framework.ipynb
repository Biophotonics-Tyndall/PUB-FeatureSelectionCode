{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Principal Component Analysis (PCA) Feature Selection (FS) Framework"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "from itertools import combinations\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "import matplotlib.transforms\n",
    "import matplotlib\n",
    "\n",
    "import time\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Disable Print\n",
    "def blockPrint():\n",
    "    sys.__stdout__ = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore Print\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to data directory\n",
    "\n",
    "work_path = os.getcwd()\n",
    "print(work_path)\n",
    "\n",
    "os.chdir('YOUR DATA DIRECTORY')\n",
    "data_path = os.getcwd()\n",
    "print(data_path)\n",
    "os.chdir(data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "os.chdir(data_path)\n",
    "\n",
    "# Load dataset - df\n",
    "df = pd.read_csv('YOUR DATA FILE.csv')\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_by_y = df.groupby(['target_y']).mean()\n",
    "stdev_df_by_y = df.groupby(['target_y']).std()\n",
    "\n",
    "# Column names to numerical\n",
    "col_wavelengths = df.columns.drop('target_y')\n",
    "col_wavelengths = col_wavelengths.astype(np.float64)\n",
    "print('Number of wavelengths: ', len(col_wavelengths))\n",
    "\n",
    "# Legend labels\n",
    "tissue_types = df['target_y'].unique()\n",
    "tissue_types.sort()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SG Smoothing of the raw data - Gentle smoothing with w/p = 2.5 to get rid of some baseline noise\n",
    "\n",
    "# Features\n",
    "X_raw = df.drop(['target_y'], axis=1)\n",
    "\n",
    "# Target\n",
    "y = df['target_y']\n",
    "\n",
    "# Spectral Smoothing - Savitzkyâ€“Golay (SG) method\n",
    "w = 5\n",
    "p = 2\n",
    "X_smooth = savgol_filter(X_raw, w, polyorder=p, axis=1, deriv=0)\n",
    "\n",
    "# Smoothed dataframe\n",
    "df_smooth = pd.DataFrame(X_smooth, columns = col_wavelengths.astype(\"string\"))\n",
    "df_smooth = pd.concat([df_smooth, y.rename('target_y')], axis=1)\n",
    "\n",
    "# Average spectra for each tissue type\n",
    "avg_df_by_y_smooth = df_smooth.groupby(['target_y']).mean()\n",
    "stdev_df_by_y_smooth = df_smooth.groupby(['target_y']).std()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save path\n",
    "os.chdir(work_path)\n",
    "os.chdir('YOUR SAVE PATH')\n",
    "save_path = os.getcwd()\n",
    "print(save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to search for the optimal number of PCA components - evaluated by LDA in this case\n",
    "\n",
    "def pca_ncomp(X_pca, y, n_comp, cv): # Change this to use GridSearchCV\n",
    "\n",
    "    # Define rmsecv as the goodness-of-fit measure\n",
    "    pca_lda_scores_avg = []\n",
    "    pca_lda_scores_std = []\n",
    "    for n in range(1, n_comp+1, 1):\n",
    "\n",
    "        # define the first n selected pc\n",
    "        X_npca_select = X_pca[:,:n]\n",
    "        # define lda regression\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        # Simple cv score\n",
    "        lda_score = cross_val_score(lda, X_npca_select, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "        # Accuracy scores\n",
    "        pca_lda_scores_avg.append(np.mean(lda_score))\n",
    "        pca_lda_scores_std.append(np.std(lda_score))\n",
    "\n",
    "    best_ncomp = np.argmax(pca_lda_scores_avg) + 1\n",
    "    lda_score_max = pca_lda_scores_avg[best_ncomp-1]\n",
    "\n",
    "    return best_ncomp, lda_score_max, pca_lda_scores_avg, pca_lda_scores_std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define temperature in Simulated Annealing\n",
    "\n",
    "def temperature_sa(accuracy_max): #-> need to fix this so that as accuracy increases, change of acceptance decreases\n",
    "    return 0.05 * (1-accuracy_max) + 0.00000001 # regularization term to avoid dividing by 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to optimize PC selection using Simulated Annealing\n",
    "\n",
    "def pc_sa_opt(X_pca, y, cv, npc_total, npc_select, n_iter):\n",
    "\n",
    "    # Set the number of principal components\n",
    "    npc_total = npc_total\n",
    "    npc_select = npc_select\n",
    "\n",
    "    # Set selected PCs - Initial condition is the first n PCs\n",
    "    idx_pc_arr = np.arange(npc_total)\n",
    "    pc_select = idx_pc_arr[:npc_select]\n",
    "    pc_exclude = idx_pc_arr[npc_select:]\n",
    "\n",
    "    # Choose the selected PCs from the PCA transformed X dataset\n",
    "    X_pca_select = X_pca[:,pc_select]\n",
    "\n",
    "    # Initialize list for storing updated clf accuracy from each iteration\n",
    "    all_clf_accuracy = []\n",
    "    all_opt_ncomp = []\n",
    "    all_pc_select = []\n",
    "    all_pc_exclude = []\n",
    "\n",
    "\n",
    "    # Calculate the initial clf accuracy score and the optimal number of PCs\n",
    "    opt_ncomp_init, lda_score_init, _, _ = pca_ncomp(X_pca_select, y, npc_select, cv=cv)\n",
    "    all_clf_accuracy.append(lda_score_init)\n",
    "    all_opt_ncomp.append(opt_ncomp_init)\n",
    "    all_pc_select.append(pc_select)\n",
    "    all_pc_exclude.append(pc_exclude)\n",
    "    print('The initial optimal number of PCA components: ', opt_ncomp_init)\n",
    "    print('The initial clf accuracy using LDA: %.5f ' % lda_score_init)\n",
    "\n",
    "    # Simulated Annealing loop\n",
    "\n",
    "    # Initialize arrays for updating\n",
    "    pc_select_update = np.copy(pc_select)\n",
    "    print('Initial Selected PCs', pc_select_update)\n",
    "    pc_exclude_update = np.copy(pc_exclude)\n",
    "    print('Initial Excluded PCs', pc_exclude_update)\n",
    "    lda_score_update = lda_score_init\n",
    "    opt_ncomp_update = opt_ncomp_init\n",
    "\n",
    "    if lda_score_init == 1:\n",
    "        print('-> LDA clf accuracy is already 100%')\n",
    "        pc_select_update = pc_select_update\n",
    "        lda_score_update = lda_score_update\n",
    "        update_count = 0\n",
    "        all_clf_accuracy = []\n",
    "        all_opt_ncomp = []\n",
    "        all_pc_select = []\n",
    "        all_pc_exclude = []\n",
    "    else:\n",
    "\n",
    "        update_count = 0\n",
    "\n",
    "        for i in range(n_iter):\n",
    "\n",
    "            print('\\n')\n",
    "            print('--- Iteration: ', i, ' ---')\n",
    "            #print('Initial clf accuracy: ', lda_score_update)\n",
    "            # Define temperature reg\n",
    "            temp_reg = temperature_sa(lda_score_update)\n",
    "            print('Temperature Reg for SA: ', temp_reg)\n",
    "            # Initialize lists for updates in the inner loop\n",
    "            pc_select_inner = np.copy(pc_select_update)\n",
    "            pc_exclude_inner = np.copy(pc_exclude_update)\n",
    "\n",
    "            # Change one element during each iteration\n",
    "            idx_select = np.random.randint(npc_select)\n",
    "            idx_exclude = np.random.randint(npc_total-npc_select)\n",
    "            item_select = pc_select_inner[idx_select]\n",
    "            print('Selected PC for Exchange: ', item_select)\n",
    "            item_exclude = pc_exclude_inner[idx_exclude]\n",
    "            print('Excluded PC for Exchange: ', item_exclude)\n",
    "            pc_select_inner[idx_select] = item_exclude\n",
    "            print('New Selected PCs: ', pc_select_inner)\n",
    "            pc_exclude_inner[idx_exclude] = item_select\n",
    "            print('New Excluded PCs: ', pc_exclude_inner)\n",
    "\n",
    "            # Select the new PCs and evaluate\n",
    "            X_pca_select_update = X_pca[:,pc_select_inner]\n",
    "            opt_ncomp_inner, lda_score_inner, _, _ = pca_ncomp(X_pca_select_update, y, npc_select, cv=cv)\n",
    "            print('Update npc: ', opt_ncomp_inner)\n",
    "            print('Update clf accuracy: %.5f ' % lda_score_inner)\n",
    "            print('Old clf accuracy: %.5f ' % lda_score_update)\n",
    "\n",
    "\n",
    "            # Make decision\n",
    "            if lda_score_inner > lda_score_update:\n",
    "                print('-> Yes higher clf accuracy')\n",
    "                # Update\n",
    "                pc_select_update = pc_select_inner\n",
    "                pc_exclude_update = pc_exclude_inner\n",
    "                opt_ncomp_update = opt_ncomp_inner\n",
    "                lda_score_update = lda_score_inner\n",
    "                update_count += 1\n",
    "                print('-> Number of updates: ', update_count)\n",
    "                # Store\n",
    "                all_clf_accuracy.append(lda_score_update)\n",
    "                all_opt_ncomp.append(opt_ncomp_update)\n",
    "                all_pc_select.append(pc_select_update)\n",
    "                all_pc_exclude.append(pc_exclude_update)\n",
    "                print('-> New PCs: ', pc_select_update)\n",
    "                print('-> New clf accuracy: %.5f ' % lda_score_update)\n",
    "                print('-> New npc: ', opt_ncomp_update)\n",
    "            elif lda_score_inner <= lda_score_update:\n",
    "                sa_prob = np.exp((lda_score_inner-lda_score_update)/temp_reg)\n",
    "                print('SA Probability: ', sa_prob)\n",
    "                if np.random.random() < sa_prob:\n",
    "                    print('-> Accepted; Lower than SA probability')\n",
    "                    # Update\n",
    "                    pc_select_update = pc_select_inner\n",
    "                    pc_exclude_update = pc_exclude_inner\n",
    "                    opt_ncomp_update = opt_ncomp_inner\n",
    "                    lda_score_update = lda_score_inner\n",
    "                    update_count += 1\n",
    "                    print('-> Number of updates: ', update_count)\n",
    "                    # Store\n",
    "                    all_clf_accuracy.append(lda_score_update)\n",
    "                    all_opt_ncomp.append(opt_ncomp_update)\n",
    "                    all_pc_select.append(pc_select_update)\n",
    "                    all_pc_exclude.append(pc_exclude_update)\n",
    "                    print('-> New PCs: ', pc_select_update)\n",
    "                    print('-> New clf accuracy: %.5f ' % lda_score_update)\n",
    "                    print('-> New npc: ', opt_ncomp_update)\n",
    "                else:\n",
    "                    print('-> Rejected')\n",
    "                    print('-> Keep Old PCs: ', pc_select_update)\n",
    "                    print('-> Keep Old Accuracy: %.5f ' % lda_score_update)\n",
    "                    # Store\n",
    "                    all_clf_accuracy.append(lda_score_update)\n",
    "                    all_opt_ncomp.append(opt_ncomp_update)\n",
    "                    all_pc_select.append(pc_select_update)\n",
    "                    all_pc_exclude.append(pc_exclude_update)\n",
    "\n",
    "    return pc_select_update, lda_score_update, all_clf_accuracy, all_opt_ncomp, all_pc_select, all_pc_exclude, update_count\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to rank and remove multicollinearity - can select top K least correlated features using Pearson correlation\n",
    "# Return indices\n",
    "\n",
    "def top_K_least_correlated(X,y, K_features, selection = f_classif):\n",
    "\n",
    "    # Select the top feature by ANOVA F-value\n",
    "    fs = SelectKBest(selection,k=\"all\")\n",
    "    fs.fit(X,y)\n",
    "    # Find the index from high to low\n",
    "    anova_ind = np.argsort(-fs.scores_)\n",
    "\n",
    "    # Initiate the search\n",
    "    selected_ind_update = [anova_ind[0]]\n",
    "    anova_ind_update = np.copy(anova_ind)\n",
    "    anova_ind_update = np.delete(anova_ind_update, 0)\n",
    "\n",
    "    while len(selected_ind_update) < K_features:\n",
    "        #print('Number of Selected Ind: ', len(selected_ind_update))\n",
    "        pearson_rank = []\n",
    "        for i in range(len(anova_ind_update)):\n",
    "            pearson_corr = np.max(np.abs(np.corrcoef(X.iloc[:, selected_ind_update + [anova_ind_update[i]]], rowvar=False))\n",
    "                                  - np.identity(len(selected_ind_update)+1))\n",
    "            pearson_rank.append(pearson_corr)\n",
    "        selected_ind = np.argsort(pearson_rank)[0]\n",
    "        selected_anova_ind = anova_ind_update[selected_ind]\n",
    "        #print('Selected Ind: ', selected_anova_ind)\n",
    "        #print('Selected Pearson Coeff: ', pearson_rank[selected_ind])\n",
    "        selected_ind_update.append(selected_anova_ind)\n",
    "        anova_ind_update = np.delete(anova_ind_update, selected_ind)\n",
    "\n",
    "    return selected_ind_update"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a function to evaluate clf accuracy using lda - Number of Features is a variable\n",
    "# F1 score calculation can be added here\n",
    "\n",
    "def clf_accuracy_eval(X, y, model, cv):\n",
    "\n",
    "    # Initiate empty lists\n",
    "    clf_accuracy_scores = [] # Calculate classification scores\n",
    "    clf_balanced_scores = [] # Calculate balanced classification scores\n",
    "    #clf_f1_scores = [] # Calculate F1 scores\n",
    "    #count = 0\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        # count+=1\n",
    "        # print(count, \" of \",  cv.get_n_splits(), \" CV folds \", end=\"\\r\")\n",
    "\n",
    "        # define model\n",
    "        clf_model = model # model needs to be refined in each loop? so move down into the loop?\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Fit model\n",
    "        clf_model.fit(X_train, y_train)\n",
    "        # Predict using the fitted model\n",
    "        y_predict = clf_model.predict(X_test)\n",
    "        # Calculate classification accuracy score\n",
    "        clf_score = accuracy_score(y_test, y_predict)\n",
    "        # Calculate classification balanced accuracy score\n",
    "        clf_balanced_score = balanced_accuracy_score(y_test, y_predict)\n",
    "        # Calculate classification F-1 score\n",
    "        #clf_f1_score = f1_score(y_test, y_predict, average='binary')\n",
    "        # Store each iteration\n",
    "        clf_accuracy_scores.append(clf_score)\n",
    "        clf_balanced_scores.append(clf_balanced_score)\n",
    "        #clf_f1_scores.append(clf_f1_score)\n",
    "\n",
    "    return clf_accuracy_scores, clf_balanced_scores #, clf_f1_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The OVO Approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save path\n",
    "os.chdir(save_path)\n",
    "os.chdir('YOUR SAVE PATH - SUBFOLDER')\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PCA Framework for the OVO approach starts here:\n",
    "\n",
    "# Separate the for loop below into batches to solve memory error\n",
    "# Or else clear all figure objects and rest python garbage collector\n",
    "\n",
    "# Define parameters\n",
    "df_dataset = df_smooth\n",
    "tissue_types = tissue_types\n",
    "\n",
    "pca_components = 30\n",
    "peak_height = 0.2\n",
    "\n",
    "random_state = 42\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)\n",
    "\n",
    "npc_total = 30\n",
    "npc_select = 10\n",
    "n_iter = 600\n",
    "\n",
    "# Define binary combinations\n",
    "list_tissue_comb = list(combinations(tissue_types,2))\n",
    "# Save the list of binary pairs\n",
    "if not os.path.exists('order_of_tissue_comb.joblib'):\n",
    "    dump(list_tissue_comb, 'order_of_tissue_comb.joblib')\n",
    "\n",
    "# Initiate lists for storing variables\n",
    "all_X_binary_pca = []\n",
    "all_pca_loadings = []\n",
    "all_total_var = []\n",
    "all_n_components = []\n",
    "all_pc_var = []\n",
    "all_sa_select_pc = []\n",
    "# Selected wavelength by find local maxima\n",
    "all_select_ind = []\n",
    "all_select_wv = []\n",
    "all_select_wv_final = []\n",
    "# Total time of execution\n",
    "total_time = []\n",
    "\n",
    "# Set custom color cycle\n",
    "custom_cycler = (cycler('color', ['#d62728', '#1f77b4', '#2ca02c', '#ff7f0e',\n",
    "                                  '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']) +\n",
    "                 cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "\n",
    "# Set matplotlib backend to non-interactive to release memory\n",
    "matplotlib.use('agg')\n",
    "\n",
    "count = 0\n",
    "for i,k in combinations(tissue_types,2): # can separate this to make an individual function\n",
    "\n",
    "    # Track timestamp - elapsed time\n",
    "    start_time = time.time()\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    # if count == 2:\n",
    "    #     print('count = 2; break')\n",
    "    #     break\n",
    "\n",
    "    print('Iteration: ', count)\n",
    "    print('First Label: ', i)\n",
    "    print('Second Label: ',k)\n",
    "\n",
    "    # Data selection\n",
    "    binary_subset = df_dataset.loc[(df['target_y'] == i) + (df['target_y'] == k)]\n",
    "\n",
    "    # Features\n",
    "    X_binary_init = binary_subset.drop(['target_y'], axis=1)\n",
    "    # Target\n",
    "    y_binary_init = binary_subset['target_y']\n",
    "    # Convert to 0 and 1 - i = 1, k = 0\n",
    "    y_binary_init = (y_binary_init == i).astype('uint8')\n",
    "\n",
    "    # Split Train Test Validation set\n",
    "    X_binary, X_val_all, y_binary, y_val_all = train_test_split(X_binary_init, y_binary_init,\n",
    "                                                                test_size=0.2, stratify=y_binary_init, random_state=random_state)\n",
    "    # Save train test sets\n",
    "    dump(X_binary, str(i) + '_' + str(k) + '_X_binary.joblib')\n",
    "    dump(X_val_all, str(i) + '_' + str(k) + '_X_val_all.joblib')\n",
    "    dump(y_binary, str(i) + '_' + str(k) + '_y_binary.joblib')\n",
    "    dump(y_val_all, str(i) + '_' + str(k) + '_y_val_all.joblib')\n",
    "\n",
    "    # PCA - can separate this to make an individual function\n",
    "    pca_model = PCA(n_components=pca_components, svd_solver = 'full')\n",
    "    X_binary_pca = pca_model.fit_transform(X_binary)\n",
    "    pca_loadings = pca_model.components_\n",
    "    total_var = pca_model.explained_variance_ratio_.sum() * 100\n",
    "    num_components = pca_model.n_components_\n",
    "    pc_var = pca_model.explained_variance_ratio_\n",
    "    #print(\"Number of Components: \", num_components)\n",
    "    # Store variables in lists\n",
    "    all_X_binary_pca.append(X_binary_pca)\n",
    "    all_pca_loadings.append(pca_loadings)\n",
    "    all_total_var.append(total_var)\n",
    "    all_n_components.append(num_components)\n",
    "    all_pc_var.append(pc_var)\n",
    "\n",
    "    # SA on PCA results - optimization\n",
    "    # A = pc_select_update\n",
    "    # B = lda_score_update\n",
    "    # C = all_clf_accuracy\n",
    "    # D = all_opt_ncomp\n",
    "    # E = all_pc_select\n",
    "    # F = all_pc_exclude\n",
    "    # G = update_count\n",
    "    blockPrint() # Block printing\n",
    "    A, B, C, D, E, F, G = pc_sa_opt(X_binary_pca, y_binary, cv=cv, npc_total=npc_total, npc_select=npc_select, n_iter=n_iter)\n",
    "    enablePrint() # Restore printing\n",
    "    print('Selected PCs: ', A)\n",
    "    all_sa_select_pc.append(A)\n",
    "\n",
    "    # Plot Optimization\n",
    "    if np.any(C):\n",
    "        print('Clf accuracy using Selected PCs: ', C[-1])\n",
    "        # Set the figure size\n",
    "        f, ax = plt.subplots(figsize=(10, 8))\n",
    "        # Tight layout\n",
    "        f.tight_layout()\n",
    "        # Plot\n",
    "        plt.plot(np.arange(n_iter+1), C, label='Clf Accuracy')\n",
    "        # Set figure object\n",
    "        ax.set_title('LDA Clf Accuracy Progression for ' + str(i) + ' vs. ' + str(k))\n",
    "        ax.set_xlabel('Iterations')\n",
    "        ax.set_ylabel('LDA Clf Accuracy (A.U.)')\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "        bbox = matplotlib.transforms.Bbox([[-0.5, -0.36], [11.45, 8.56]])\n",
    "        # Save figure\n",
    "        if not os.path.exists(str(i) + '_' + str(k) + '_LDA_clf_accuracy_opt.png'):\n",
    "            f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_LDA_clf_accuracy_opt.png', dpi = 1080, bbox_inches =bbox)\n",
    "        f.clear()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        plt.close()\n",
    "        gc.collect()\n",
    "\n",
    "    else:\n",
    "        print('Clf accuracy using Selected PCs: 100%')\n",
    "\n",
    "\n",
    "    # PC plot labels - can separate this to make an individual function\n",
    "    labels = {str(c): f\"PC {i+1} ({var:.1f}%)\"\n",
    "              for c, i, var in zip(range(len(A)), A, pca_model.explained_variance_ratio_[A] * 100)}\n",
    "    labels['color'] = 'Tissue Types'\n",
    "    # PCA Scatter plot\n",
    "    selected_pca_var = pca_model.explained_variance_ratio_[A].sum() * 100\n",
    "    fig = px.scatter_matrix(X_binary_pca[:, A],\n",
    "                            color=y_binary,\n",
    "                            dimensions=range(len(A)),\n",
    "                            labels=labels,\n",
    "                            title=f'PCA Total Explained Variance: {selected_pca_var:.3f}%',\n",
    "                            width = 1100,\n",
    "                            height = 1100,\n",
    "                            template='ggplot2')\n",
    "    fig.update_layout(font=dict(size=10))\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "    fig.update_xaxes(automargin=True)\n",
    "    fig.update_yaxes(automargin=True)\n",
    "    # Save figure\n",
    "    if not os.path.exists(str(i) + '_' + str(k) + '_pca.png'):\n",
    "        fig.write_image(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_pca.png', scale = 2)\n",
    "    # Close figure\n",
    "    fig.data = []\n",
    "    fig.layout = {}\n",
    "\n",
    "    # PCA Loadings Plot - can separate this to make an individual function\n",
    "    # Set the figure size\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Tight layout\n",
    "    f.tight_layout()\n",
    "    # Set colors\n",
    "    ax.set_prop_cycle(custom_cycler)\n",
    "    #plt.style.library['tableau-colorblind10']\n",
    "    # Labels\n",
    "    labels = ['PC ' + str(i + 1) for i in A]\n",
    "    # Plot\n",
    "    plt.plot(col_wavelengths, abs(pca_loadings[A,:]).T, label=labels)\n",
    "    # Set figure object\n",
    "    ax.set_title('PCA Loadings for ' + str(i) + ' vs. ' + str(k))\n",
    "    ax.set_xlabel('Wavelength (nm)')\n",
    "    ax.set_ylabel('PCA Loadings (A.U.)')\n",
    "    ax.set_xlim([350, 1850])\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    bbox = matplotlib.transforms.Bbox([[-0.2, -0.36], [11.45, 8.56]])\n",
    "    # Save figure\n",
    "    if not os.path.exists(str(i) + '_' + str(k) + '_PCA_loadings.png'):\n",
    "        f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_PCA_loadings.png', dpi = 1080, bbox_inches =bbox)\n",
    "    f.clear()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "    # Find PCA loadings peak values - can separate this to make an individual function\n",
    "    # Scale each abs PCA loading curve between 0 and 1\n",
    "    max_pts = np.max(abs(pca_loadings[A,:]), axis = 1)\n",
    "    norm_abs_pca_loadings = (abs(pca_loadings[A,:]).T/max_pts).T\n",
    "    # Find indices of local peaks by user defined criteria\n",
    "    all_peaks_pca = np.array([]).astype(int)\n",
    "    for n in range(len(norm_abs_pca_loadings)):\n",
    "        # calculate peak prominence for setting threshold\n",
    "        peaks_pca_prominence, _ = find_peaks(norm_abs_pca_loadings[n], distance=20) # 20 to indicate a typical LED FWHM\n",
    "        avg_prominence = np.mean(peak_prominences(norm_abs_pca_loadings[n], peaks_pca_prominence)[0])\n",
    "        # refine peak selection; height = 0.2 to further remove baseline noises\n",
    "        peaks_pca, _ = find_peaks(norm_abs_pca_loadings[n], height=peak_height, distance=20, prominence=avg_prominence)\n",
    "        all_peaks_pca = np.concatenate([all_peaks_pca, peaks_pca], axis=None)\n",
    "    # Find duplicate peaks among all PCs and remove nearby neighbors\n",
    "    all_peaks_pca=list(dict.fromkeys(all_peaks_pca))\n",
    "    peak_dup = []\n",
    "    for x, y in combinations(all_peaks_pca,2):\n",
    "        if abs(col_wavelengths[x]-col_wavelengths[y])<=20:\n",
    "            ind = np.where(all_peaks_pca==y)[0][0]\n",
    "            peak_dup.append(ind)\n",
    "\n",
    "    # Remove duplicated indices\n",
    "    peak_dup = np.unique(peak_dup)\n",
    "    # Remove the peaks\n",
    "    if np.any(peak_dup):\n",
    "        all_peaks_pca_final = np.delete(all_peaks_pca, peak_dup)\n",
    "    else:\n",
    "        all_peaks_pca_final = all_peaks_pca\n",
    "    # Store\n",
    "    all_select_ind.append(all_peaks_pca_final)\n",
    "    all_select_wv.append(col_wavelengths[all_peaks_pca_final])\n",
    "    print('Number of Selected Wavelength: ', len(col_wavelengths[all_peaks_pca_final]))\n",
    "    print('Selected Wavelength: ', col_wavelengths[all_peaks_pca_final])\n",
    "    #print('\\n')\n",
    "\n",
    "    # Plot selected wavelengths on PC 1 - can separate this to make an individual function\n",
    "    # Set the figure size\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Tight layout\n",
    "    f.tight_layout()\n",
    "    # Set colors\n",
    "    ax.set_prop_cycle(custom_cycler)\n",
    "    #plt.style.library['tableau-colorblind10']\n",
    "    # Plot\n",
    "    plt.plot(col_wavelengths, abs(pca_loadings[A,:]).T, label=labels)\n",
    "    plt.plot(col_wavelengths[all_peaks_pca_final], abs(pca_loadings[A,:]).T[:,0][all_peaks_pca_final], \"ko\")\n",
    "    # Set figure object\n",
    "    ax.set_title('Selected Peaks for ' + str(i) + ' vs. ' + str(k))\n",
    "    ax.set_xlabel('Wavelength (nm)')\n",
    "    ax.set_ylabel('PCA Loadings (A.U.)')\n",
    "    ax.set_xlim([350, 1850])\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    bbox = matplotlib.transforms.Bbox([[-0.45, -1.3], [11.45, 8.56]])\n",
    "    # Add text - selected wavelengths\n",
    "    plt.text(0, -0.13, 'Selected Wavelength: ' + str(np.sort(np.array(col_wavelengths[all_peaks_pca_final]))), horizontalalignment='left',\n",
    "             verticalalignment = 'center_baseline', transform=ax.transAxes)\n",
    "    # Save figure\n",
    "    if not os.path.exists(str(i) + '_' + str(k) + '_PCA_peaks.png'):\n",
    "        f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_PCA_peaks.png', dpi = 1080, bbox_inches =bbox)\n",
    "    #plt.close()\n",
    "    f.clear()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "    # Select a fixed number of wavelengths - K = 10\n",
    "    if len(all_peaks_pca_final)>=10:\n",
    "        final_select_wv = top_K_least_correlated(X_binary.iloc[:,all_peaks_pca_final],y_binary, K_features=10, selection = f_classif)\n",
    "    else:\n",
    "        final_select_wv = top_K_least_correlated(X_binary.iloc[:,all_peaks_pca_final],y_binary,\n",
    "                                                 K_features=len(all_peaks_pca_final), selection = f_classif)\n",
    "    all_select_wv_final.append(col_wavelengths[all_peaks_pca_final][final_select_wv])\n",
    "    print('Final Selected Wavelength: ', col_wavelengths[all_peaks_pca_final][final_select_wv])\n",
    "\n",
    "    # Plot selected wavelengths on DRS measurements - can separate this to make an individual function\n",
    "    # Average spectra for each tissue type\n",
    "    avg_df_select_tissues = binary_subset.groupby(['target_y']).mean()\n",
    "    stdev_df_select_tissues = binary_subset.groupby(['target_y']).std()\n",
    "    # Set the figure size\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Tight layout\n",
    "    f.tight_layout()\n",
    "    # Set colors\n",
    "    ax.set_prop_cycle(custom_cycler)\n",
    "    # Plot\n",
    "    select_tissue_label = [i,k]\n",
    "    for tissue in range(avg_df_select_tissues.shape[0]):\n",
    "        plt.plot(col_wavelengths, avg_df_select_tissues.iloc[tissue,:], label = select_tissue_label[tissue])\n",
    "        pos_std = avg_df_select_tissues.iloc[tissue,:] + stdev_df_select_tissues.iloc[tissue,:]\n",
    "        neg_std = avg_df_select_tissues.iloc[tissue,:] - stdev_df_select_tissues.iloc[tissue,:]\n",
    "        ax.fill_between(col_wavelengths, neg_std, pos_std, alpha = 0.08)\n",
    "    for wv in col_wavelengths[all_peaks_pca_final][final_select_wv]:\n",
    "        plt.axvline(x=wv, color='#2ca02c', linestyle='-', alpha=0.6, lw=1.75)\n",
    "    # Add text - selected wavelengths\n",
    "    plt.text(0, -0.12, 'Final Selected Wavelength: '+\n",
    "             str(np.array(col_wavelengths[all_peaks_pca_final][final_select_wv])),\n",
    "             horizontalalignment='left', verticalalignment = 'center_baseline', transform=ax.transAxes)\n",
    "    # Set figure object\n",
    "    ax.set_title('Selected Peaks for ' + str(i) + ' vs. ' + str(k))\n",
    "    ax.set_xlabel('Wavelength (nm)')\n",
    "    ax.set_ylabel('Normalized Intensity (A.U.)')\n",
    "    ax.set_xlim([350, 1850])\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    bbox = matplotlib.transforms.Bbox([[-0.45, -1.3], [11.45, 8.56]])\n",
    "    # Save figure\n",
    "    if not os.path.exists(str(i) + '_' + str(k) + '_PCA_select_wv.png'):\n",
    "        f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_PCA_select_wv.png', dpi = 1080, bbox_inches =bbox)\n",
    "    #plt.close()\n",
    "    f.clear()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # End timestamp\n",
    "    end_time = time.time()\n",
    "    print('Time to run: ', (end_time - start_time)/60, ' minutes')\n",
    "    total_time.append(end_time - start_time)\n",
    "    print('\\n')\n",
    "\n",
    "print('Total time to run: ', sum(total_time)/3600, ' hours')\n",
    "print('END')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save variables\n",
    "\n",
    "# dump(all_X_binary_pca, 'all_X_binary_pca.joblib')\n",
    "# dump(all_pca_loadings, 'all_pca_loadings.joblib')\n",
    "# dump(all_total_var, 'all_total_var.joblib')\n",
    "# dump(all_n_components, 'all_n_components.joblib')\n",
    "# dump(all_pc_var, 'all_pc_var.joblib')\n",
    "# dump(all_sa_select_pc, 'all_sa_select_pc.joblib')\n",
    "#\n",
    "# dump(all_select_ind, 'all_select_ind.joblib')\n",
    "# dump(all_select_wv, 'all_select_wv.joblib')\n",
    "# dump(all_select_wv_final, 'all_select_wv_final.joblib')\n",
    "#\n",
    "# dump(total_time, 'total_time.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The OVR Approach"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change to save_path\n",
    "os.chdir(save_path)\n",
    "os.chdir('YOUR SAVE PATH - SUBFOLDER')\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "df_dataset = df_smooth\n",
    "\n",
    "# Tissue labels\n",
    "tissue_types = tissue_types\n",
    "\n",
    "# Set global random state\n",
    "random_state = 42\n",
    "\n",
    "# Define cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One vs Rest\n",
    "\n",
    "# Bone Cement = 1 vs. [Cortical Bone, Trabecular Bone, Cartilage, Bone Marrow] = 0\n",
    "i = 'boneCement'\n",
    "k_1 = 'cortBone'\n",
    "k_2 = 'traBone'\n",
    "k_3 = 'cartilage'\n",
    "k_4 = 'boneMarrow'\n",
    "\n",
    "# Cortical Bone = 1 vs. [Trabecular Bone, Cartilage, Bone Marrow, Muscle] = 0\n",
    "# i = 'cortBone'\n",
    "# k_1 = 'traBone'\n",
    "# k_2 = 'muscle'\n",
    "# k_3 = 'cartilage'\n",
    "# k_4 = 'boneMarrow'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('First Label: ', i)\n",
    "#print('Second Label: ',k)\n",
    "print('Second Label: ' + k_1 + ', ' + k_2 + ', ' + k_3 + ', ' + k_4)\n",
    "\n",
    "# Data selection for multiple tissue types\n",
    "df_subset = df_dataset[df_dataset['target_y'].isin([i,k_1,k_2,k_3,k_4])]\n",
    "binary_subset = df_dataset[df_dataset['target_y'].isin([i,k_1,k_2,k_3,k_4])]\n",
    "binary_subset.loc[df['target_y'].isin([k_1, k_2, k_3, k_4]), 'target_y'] = 'rest'\n",
    "binary_subset.loc[df['target_y'].isin([i]), 'target_y'] = i\n",
    "k = 'rest'\n",
    "\n",
    "# Features\n",
    "X_binary_init = binary_subset.drop(['target_y'], axis=1)\n",
    "# Target\n",
    "y_binary_init = binary_subset['target_y']\n",
    "# Convert to 0 and 1 - i = 1, k = 0\n",
    "y_binary_init = (y_binary_init == i).astype('uint8')\n",
    "\n",
    "# Split Train Test Validation set\n",
    "X_binary, X_val_all, y_binary, y_val_all = train_test_split(X_binary_init, y_binary_init,\n",
    "                                                            test_size=0.2, stratify=y_binary_init, random_state=random_state)\n",
    "\n",
    "# Save train test sets\n",
    "dump(X_binary, str(i) + '_' + str(k) + '_X_binary.joblib')\n",
    "dump(X_val_all, str(i) + '_' + str(k) + '_X_val_all.joblib')\n",
    "dump(y_binary, str(i) + '_' + str(k) + '_y_binary.joblib')\n",
    "dump(y_val_all, str(i) + '_' + str(k) + '_y_val_all.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "pca_components = 30\n",
    "peak_height = 0.2\n",
    "\n",
    "npc_total = 30\n",
    "npc_select = 10\n",
    "n_iter = 600\n",
    "\n",
    "# Set custom color cycle\n",
    "custom_cycler = (cycler('color', ['#d62728', '#1f77b4', '#2ca02c', '#ff7f0e',\n",
    "                                  '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']) +\n",
    "                 cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "\n",
    "# # Set matplotlib backend to non-interactive\n",
    "# matplotlib.use('agg')\n",
    "\n",
    "# Track timestamp - elapsed time\n",
    "start_time = time.time()\n",
    "\n",
    "print('First Label: ', i)\n",
    "print('Second Label: ' + k_1 + ', ' + k_2 + ', ' + k_3 + ', ' + k_4)\n",
    "\n",
    "# PCA - can separate this to make an individual function\n",
    "pca_model = PCA(n_components=pca_components, svd_solver = 'full')\n",
    "X_binary_pca = pca_model.fit_transform(X_binary)\n",
    "pca_loadings = pca_model.components_\n",
    "total_var = pca_model.explained_variance_ratio_.sum() * 100\n",
    "num_components = pca_model.n_components_\n",
    "pc_var = pca_model.explained_variance_ratio_\n",
    "\n",
    "# Store variables in lists\n",
    "dump(X_binary_pca, str(i) + '_' + str(k) + '_X_binary_pca.joblib')\n",
    "dump(pca_loadings, str(i) + '_' + str(k) + '_pca_loadings.joblib')\n",
    "dump(total_var, str(i) + '_' + str(k) + '_total_var.joblib')\n",
    "dump(num_components, str(i) + '_' + str(k) + '_num_components.joblib')\n",
    "dump(pc_var, str(i) + '_' + str(k) + '_pc_var.joblib')\n",
    "\n",
    "# SA on PCA results - optimization\n",
    "# A = pc_select_update\n",
    "# B = lda_score_update\n",
    "# C = all_clf_accuracy\n",
    "# D = all_opt_ncomp\n",
    "# E = all_pc_select\n",
    "# F = all_pc_exclude\n",
    "# G = update_count\n",
    "blockPrint()\n",
    "A, B, C, D, E, F, G = pc_sa_opt(X_binary_pca, y_binary, cv=cv, npc_total=npc_total, npc_select=npc_select, n_iter=n_iter)\n",
    "enablePrint()\n",
    "print('Selected PCs: ', A)\n",
    "dump(A, str(i) + '_' + str(k) + '_sa_select_pc.joblib')\n",
    "\n",
    "# Plot SA Optimization\n",
    "if np.any(C):\n",
    "    print('Clf accuracy using Selected PCs: ', C[-1])\n",
    "    # Set the figure size\n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Tight layout\n",
    "    f.tight_layout()\n",
    "    # Plot\n",
    "    plt.plot(np.arange(n_iter+1), C, label='Clf Accuracy')\n",
    "    # Set figure object\n",
    "    ax.set_title('LDA Clf Accuracy Progression for ' + str(i) + ' vs. ' + str(k))\n",
    "    ax.set_xlabel('Iterations')\n",
    "    ax.set_ylabel('LDA Clf Accuracy (A.U.)')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "    bbox = matplotlib.transforms.Bbox([[-0.5, -0.36], [11.45, 8.56]])\n",
    "    # Save figure\n",
    "    if not os.path.exists(str(i) + '_' + str(k) + '_LDA_clf_accuracy_opt.png'):\n",
    "        f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_LDA_clf_accuracy_opt.png', dpi = 1080, bbox_inches =bbox)\n",
    "    f.clear()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "else:\n",
    "    print('Clf accuracy using Selected PCs: 100%')\n",
    "\n",
    "\n",
    "# PC plot labels - can separate this to make an individual function\n",
    "labels = {str(c): f\"PC {i+1} ({var:.1f}%)\"\n",
    "          for c, i, var in zip(range(len(A)), A, pca_model.explained_variance_ratio_[A] * 100)}\n",
    "labels['color'] = 'Tissue Types'\n",
    "# PCA Scatter plot\n",
    "selected_pca_var = pca_model.explained_variance_ratio_[A].sum() * 100\n",
    "fig = px.scatter_matrix(X_binary_pca[:, A],\n",
    "                        color=y_binary,\n",
    "                        dimensions=range(len(A)),\n",
    "                        labels=labels,\n",
    "                        title=f'PCA Total Explained Variance: {selected_pca_var:.3f}%',\n",
    "                        width = 1100,\n",
    "                        height = 1100,\n",
    "                        template='ggplot2')\n",
    "fig.update_layout(font=dict(size=10))\n",
    "fig.update_traces(diagonal_visible=False)\n",
    "fig.update_xaxes(automargin=True)\n",
    "fig.update_yaxes(automargin=True)\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_pca.png'):\n",
    "    fig.write_image(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_pca.png', scale = 2)\n",
    "# Close figure\n",
    "fig.data = []\n",
    "fig.layout = {}\n",
    "\n",
    "# PCA Loadings Plot - can separate this to make an individual function\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Set colors\n",
    "ax.set_prop_cycle(custom_cycler)\n",
    "#plt.style.library['tableau-colorblind10']\n",
    "# Labels\n",
    "labels = ['PC ' + str(i + 1) for i in A]\n",
    "# Plot\n",
    "plt.plot(col_wavelengths, abs(pca_loadings[A,:]).T, label=labels)\n",
    "# Set figure object\n",
    "ax.set_title('PCA Loadings for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('PCA Loadings (A.U.)')\n",
    "ax.set_xlim([350, 1850])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "bbox = matplotlib.transforms.Bbox([[-0.2, -0.36], [11.45, 8.56]])\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_PCA_loadings.png'):\n",
    "    f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_PCA_loadings.png', dpi = 1080, bbox_inches =bbox)\n",
    "f.clear()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close('all')\n",
    "plt.close()\n",
    "gc.collect()\n",
    "\n",
    "# Find PCA loadings peak values - can separate this to make an individual function\n",
    "# Scale each abs PCA loading curve between 0 and 1\n",
    "max_pts = np.max(abs(pca_loadings[A,:]), axis = 1)\n",
    "norm_abs_pca_loadings = (abs(pca_loadings[A,:]).T/max_pts).T\n",
    "# Find indices of local peaks by user defined criteria\n",
    "all_peaks_pca = np.array([]).astype(int)\n",
    "for n in range(len(norm_abs_pca_loadings)):\n",
    "    # calculate peak prominence for setting threshold\n",
    "    peaks_pca_prominence, _ = find_peaks(norm_abs_pca_loadings[n], distance=20) # 20 to indicate a typical LED FWHM\n",
    "    avg_prominence = np.mean(peak_prominences(norm_abs_pca_loadings[n], peaks_pca_prominence)[0])\n",
    "    # refine peak selection; height = 0.2 to further remove baseline noises\n",
    "    peaks_pca, _ = find_peaks(norm_abs_pca_loadings[n], height=peak_height, distance=20, prominence=avg_prominence)\n",
    "    all_peaks_pca = np.concatenate([all_peaks_pca, peaks_pca], axis=None)\n",
    "# Find duplicate peaks among all PCs and remove nearby neighbors\n",
    "all_peaks_pca=list(dict.fromkeys(all_peaks_pca))\n",
    "peak_dup = []\n",
    "for x, y in combinations(all_peaks_pca,2):\n",
    "    if abs(col_wavelengths[x]-col_wavelengths[y])<=20:\n",
    "        ind = np.where(all_peaks_pca==y)[0][0]\n",
    "        peak_dup.append(ind)\n",
    "\n",
    "# Remove duplicated indices\n",
    "peak_dup = np.unique(peak_dup)\n",
    "# Remove the peaks\n",
    "if np.any(peak_dup):\n",
    "    all_peaks_pca_final = np.delete(all_peaks_pca, peak_dup)\n",
    "else:\n",
    "    all_peaks_pca_final = all_peaks_pca\n",
    "# Store\n",
    "dump(all_peaks_pca_final, str(i) + '_' + str(k) + '_select_ind.joblib')\n",
    "dump(col_wavelengths[all_peaks_pca_final], str(i) + '_' + str(k) + '_select_wv.joblib')\n",
    "print('Number of Selected Wavelength: ', len(col_wavelengths[all_peaks_pca_final]))\n",
    "print('Selected Wavelength: ', col_wavelengths[all_peaks_pca_final])\n",
    "\n",
    "# Plot selected wavelengths on PC 1 - can separate this to make an individual function\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Set colors\n",
    "ax.set_prop_cycle(custom_cycler)\n",
    "#plt.style.library['tableau-colorblind10']\n",
    "# Plot\n",
    "plt.plot(col_wavelengths, abs(pca_loadings[A,:]).T, label=labels)\n",
    "plt.plot(col_wavelengths[all_peaks_pca_final], abs(pca_loadings[A,:]).T[:,0][all_peaks_pca_final], \"ko\")\n",
    "# Set figure object\n",
    "ax.set_title('Selected Peaks for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('PCA Loadings (A.U.)')\n",
    "ax.set_xlim([350, 1850])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "bbox = matplotlib.transforms.Bbox([[-0.45, -1.3], [11.45, 8.56]])\n",
    "# Add text - selected wavelengths\n",
    "plt.text(0, -0.13, 'Selected Wavelength: ' + str(np.sort(np.array(col_wavelengths[all_peaks_pca_final]))), horizontalalignment='left',\n",
    "         verticalalignment = 'center_baseline', transform=ax.transAxes)\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_PCA_peaks.png'):\n",
    "    f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_PCA_peaks.png', dpi = 1080, bbox_inches =bbox)\n",
    "f.clear()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close('all')\n",
    "plt.close()\n",
    "gc.collect()\n",
    "\n",
    "# Select a fixed number of wavelengths - K = 10\n",
    "if len(all_peaks_pca_final)>=10:\n",
    "    final_select_wv = top_K_least_correlated(X_binary.iloc[:,all_peaks_pca_final],y_binary, K_features=10, selection = f_classif)\n",
    "else:\n",
    "    final_select_wv = top_K_least_correlated(X_binary.iloc[:,all_peaks_pca_final],y_binary,\n",
    "                                             K_features=len(all_peaks_pca_final), selection = f_classif)\n",
    "dump(col_wavelengths[all_peaks_pca_final][final_select_wv], str(i) + '_' + str(k) + '_select_wv_final.joblib')\n",
    "print('Final Selected Wavelength: ', col_wavelengths[all_peaks_pca_final][final_select_wv])\n",
    "# Plot selected wavelengths on DRS measurements - can separate this to make an individual function\n",
    "# Average spectra for each tissue type\n",
    "avg_df_select_tissues = df_subset.groupby(['target_y']).mean()\n",
    "stdev_df_select_tissues = df_subset.groupby(['target_y']).std()\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(10, 8))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "# Plot\n",
    "select_tissue_label = [i,k_1,k_2,k_3,k_4]\n",
    "select_tissue_label.sort()\n",
    "# Set custom color cycle\n",
    "custom_cycler_1 = (cycler('color', ['#808080', '#808080', '#d62728', '#808080', '#808080']) +\n",
    "                   cycler(lw=[1.5, 1.5, 1.5, 1.5, 1.5]))\n",
    "# Set colors\n",
    "ax.set_prop_cycle(custom_cycler_1)\n",
    "for tissue in range(avg_df_select_tissues.shape[0]):\n",
    "    plt.plot(col_wavelengths, avg_df_select_tissues.iloc[tissue,:], label = select_tissue_label[tissue])\n",
    "    pos_std = avg_df_select_tissues.iloc[tissue,:] + stdev_df_select_tissues.iloc[tissue,:]\n",
    "    neg_std = avg_df_select_tissues.iloc[tissue,:] - stdev_df_select_tissues.iloc[tissue,:]\n",
    "    ax.fill_between(col_wavelengths, neg_std, pos_std, alpha = 0.08)\n",
    "for wv in col_wavelengths[all_peaks_pca_final][final_select_wv]:\n",
    "    plt.axvline(x=wv, color='#2ca02c', linestyle='-', alpha=0.6, lw=1.75)\n",
    "# Add text - selected wavelengths\n",
    "plt.text(0, -0.12, 'Final Selected Wavelength: '+\n",
    "         str(np.array(col_wavelengths[all_peaks_pca_final][final_select_wv])),\n",
    "         horizontalalignment='left', verticalalignment = 'center_baseline', transform=ax.transAxes)\n",
    "# Set figure object\n",
    "ax.set_title('Selected Peaks for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelength (nm)')\n",
    "ax.set_ylabel('Normalized Intensity (A.U.)')\n",
    "ax.set_xlim([350, 1850])\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "bbox = matplotlib.transforms.Bbox([[-0.45, -1.3], [11.45, 8.56]])\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_PCA_select_wv.png'):\n",
    "    f.savefig(os.getcwd() + '/' +  str(i) + '_' + str(k) + '_PCA_select_wv.png', dpi = 1080, bbox_inches =bbox)\n",
    "#plt.close()\n",
    "f.clear()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close('all')\n",
    "plt.close()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# End timestamp\n",
    "end_time = time.time()\n",
    "print('Time to run: ', (end_time - start_time)/60, ' minutes')\n",
    "dump(end_time - start_time, str(i) + '_' + str(k) + '_total_time.joblib')\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot Accuracy vs. Number of Features in the order given by the algorithm\n",
    "- or can rank the order by f_classif scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the final selected wavelengths\n",
    "select_wv_final = load('YOUR SELECTED WAVELENGTHS.joblib') # in float; or use the variable directly from above\n",
    "select_wv_final_str = [str(x) for x in select_wv_final] # convert to string if float\n",
    "print('Final wv:, ', select_wv_final_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "df_dataset = df_smooth\n",
    "\n",
    "# Tissue types\n",
    "i = 'boneCement'\n",
    "k_1 = 'cortBone'\n",
    "k_2 = 'traBone'\n",
    "k_3 = 'cartilage'\n",
    "k_4 = 'boneMarrow'\n",
    "\n",
    "# i = 'cortBone'\n",
    "# k_1 = 'traBone'\n",
    "# k_2 = 'muscle'\n",
    "# k_3 = 'cartilage'\n",
    "# k_4 = 'boneMarrow'\n",
    "\n",
    "k = 'rest'\n",
    "\n",
    "# Select from the original dataset\n",
    "#df_subset = df_dataset[df_dataset['target_y'].isin([i,k_1,k_2,k_3,k_4])]\n",
    "\n",
    "# Features - Bone Cement\n",
    "X_binary = load('boneCement_rest_X_binary.joblib') # train/test\n",
    "X_val = load('boneCement_rest_X_val_all.joblib') # validation\n",
    "# Target\n",
    "y_binary = load('boneCement_rest_y_binary.joblib') # train/test\n",
    "y_val = load('boneCement_rest_y_val_all.joblib') # validation\n",
    "\n",
    "# Features - Cortical Bone\n",
    "# X_binary = load('cortBone_rest_X_binary.joblib') # train/test\n",
    "# X_val = load('cortBone_rest_X_val_all.joblib') # validation\n",
    "# # Target\n",
    "# y_binary = load('cortBone_rest_y_binary.joblib') # train/test\n",
    "# y_val = load('cortBone_rest_y_val_all.joblib') # validation\n",
    "\n",
    "# Select the features\n",
    "selected_X_binary = X_binary.loc[:, select_wv_final_str]\n",
    "selected_X_val = X_val.loc[:, select_wv_final_str]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate clf accuracy\n",
    "# Can add F1 score calculation here\n",
    "\n",
    "# Define cross validation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=random_state)\n",
    "\n",
    "all_lda_scores = []\n",
    "all_lda_stdev = []\n",
    "all_lda_scores_val = []\n",
    "all_lda_stdev_val = []\n",
    "\n",
    "all_lda_balanced_scores = []\n",
    "all_lda_balanced_stdev = []\n",
    "all_lda_balanced_scores_val = []\n",
    "all_lda_balanced_stdev_val = []\n",
    "\n",
    "for wv in range(len(select_wv_final_str)):\n",
    "    # Define LDA model\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    #model = RandomForestClassifier()\n",
    "\n",
    "    # Calculate clf accuracy cv\n",
    "    print('Number of Features: ', wv+1)\n",
    "    lda_cv_scores, lda_balanced_scores = clf_accuracy_eval(selected_X_binary.iloc[:,0:wv+1], y_binary, model, cv)\n",
    "    lda_cv_scores_val, lda_balanced_scores_val = clf_accuracy_eval(selected_X_val.iloc[:,0:wv+1], y_val, model, cv)\n",
    "\n",
    "    all_lda_scores.append(np.mean(lda_cv_scores))\n",
    "    all_lda_stdev.append(np.std(lda_cv_scores))\n",
    "    all_lda_balanced_scores.append(np.mean(lda_balanced_scores))\n",
    "    all_lda_balanced_stdev.append(np.std(lda_balanced_scores))\n",
    "\n",
    "    all_lda_scores_val.append(np.mean(lda_cv_scores_val))\n",
    "    all_lda_stdev_val.append(np.std(lda_cv_scores_val))\n",
    "    all_lda_balanced_scores_val.append(np.mean(lda_balanced_scores_val))\n",
    "    all_lda_balanced_stdev_val.append(np.std(lda_balanced_scores_val))\n",
    "\n",
    "# Save variables\n",
    "dump(all_lda_scores, str(i) + '_' + str(k) + '_lda_score_train.joblib')\n",
    "dump(all_lda_stdev, str(i) + '_' + str(k) + '_lda_std_train.joblib')\n",
    "dump(all_lda_balanced_scores, str(i) + '_' + str(k) + '_lda_balanced_train.joblib')\n",
    "dump(all_lda_balanced_stdev, str(i) + '_' + str(k) + '_lda_balanced_std_train.joblib')\n",
    "\n",
    "dump(all_lda_scores_val, str(i) + '_' + str(k) + '_lda_score_val.joblib')\n",
    "dump(all_lda_stdev_val, str(i) + '_' + str(k) + '_lda_std_val.joblib')\n",
    "dump(all_lda_balanced_scores_val, str(i) + '_' + str(k) + '_lda_balanced_val.joblib')\n",
    "dump(all_lda_balanced_stdev_val, str(i) + '_' + str(k) + '_lda_balanced_std_val.joblib')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Accuracy on train\n",
    "plt.plot(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_scores, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_scores, yerr=all_lda_stdev,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + select_wv_final_str\n",
    "plt.xticks(np.arange(0, len(select_wv_final_str) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_accuracy_nFeatures_train.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_accuracy_nFeatures_train.png', dpi=1080,\n",
    "              bbox_inches=bbox)\n",
    "\n",
    "\n",
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Accuracy on validation\n",
    "plt.plot(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_scores_val, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_scores_val,\n",
    "             yerr=all_lda_stdev_val, fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + select_wv_final_str\n",
    "plt.xticks(np.arange(0, len(select_wv_final_str) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_accuracy_nFeatures_val.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_accuracy_nFeatures_val.png', dpi=1080, bbox_inches=bbox)\n",
    "\n",
    "\n",
    "# plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Balanced accuracy on train\n",
    "plt.plot(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_balanced_scores, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_balanced_scores,\n",
    "             yerr=all_lda_balanced_stdev,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + select_wv_final_str\n",
    "plt.xticks(np.arange(0, len(select_wv_final_str) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_balanced_nFeatures_train.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_balanced_nFeatures_train.png', dpi=1080,\n",
    "              bbox_inches=bbox)\n",
    "\n",
    "\n",
    "# Plot Clf Accuracy vs. Number of Features\n",
    "\n",
    "# Set the figure size\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "# Tight layout\n",
    "f.tight_layout()\n",
    "\n",
    "# Plot - Balanced accuracy on validation\n",
    "plt.plot(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_balanced_scores_val, '--', lw=2.5)\n",
    "plt.errorbar(np.linspace(1, len(select_wv_final_str), len(select_wv_final_str)), all_lda_balanced_scores_val,\n",
    "             yerr=all_lda_balanced_stdev_val,\n",
    "             fmt='o', capsize=1.5)\n",
    "xlabels = ['0'] + select_wv_final_str\n",
    "plt.xticks(np.arange(0, len(select_wv_final_str) + 1, 1), xlabels)\n",
    "# Set figure object\n",
    "ax.set_title('Classification Accuracy vs. Number of Wavelengths for ' + str(i) + ' vs. ' + str(k))\n",
    "ax.set_xlabel('Wavelengths Included (nm)')\n",
    "ax.set_ylabel('LDA Clf Accuracy')\n",
    "#ax.set_xlim([350, 1850])\n",
    "bbox = matplotlib.transforms.Bbox([[-0.4, -0.4], [8.5, 6.5]])\n",
    "\n",
    "# Save figure\n",
    "if not os.path.exists(str(i) + '_' + str(k) + '_balanced_nFeatures_val.png'):\n",
    "    f.savefig(os.getcwd() + '/' + str(i) + '_' + str(k) + '_balanced_nFeatures_val.png', dpi=1080, bbox_inches=bbox)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}